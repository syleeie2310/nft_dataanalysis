# Databricks notebook source
import numpy as np
import pandas as pd
from statsmodels.tsa.ar_model import AR
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, acf, pacf
import matplotlib.pyplot as plt
import seaborn as sb
from warnings import filterwarnings
filterwarnings("ignore")
plt.style.use("ggplot")
pd.options.display.float_format = '{:.2f}'.format

# COMMAND ----------

# MAGIC %md
# MAGIC # ë°ì´í„° ë¡œë“œ

# COMMAND ----------

data = pd.read_csv('/dbfs/FileStore/nft/nft_market_cleaned/total_220222_cleaned.csv', index_col = "Date", parse_dates=True, thousands=',')

# COMMAND ----------

data.info()

# COMMAND ----------

data.head()

# COMMAND ----------

data.tail()

# COMMAND ----------

# MAGIC %md
# MAGIC # Cross Correlation(ìƒí˜¸ìƒê´€ë¶„ì„)
# MAGIC - ìœ„í‚¤í”¼ë””ì•„: https://en.wikipedia.org/wiki/Cross-correlation
# MAGIC - 1d ë°°ì—´ : statsmodelCCF, numpy.correlate, matplotlib.pyplot.xcorr(numpy.correlate ê¸°ë°˜)
# MAGIC   - https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.ccf.html
# MAGIC   - https://numpy.org/doc/stable/reference/generated/numpy.correlate.html#numpy.correlate
# MAGIC   - numpy.correlateFFTë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨ë³¼ë£¨ì…˜ì„ ê³„ì‚°í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í° ë°°ì—´(ì¦‰, n = 1e5)ì—ì„œ ëŠë¦¬ê²Œ ìˆ˜í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° scipy.signal.correlateë°”ëŒì§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# MAGIC - 2d ë°°ì—´ : scipy.signal.correlate2d , scipy.stsci.convolve.correlate2d 
# MAGIC - êµì°¨ ë° ì‹œì°¨ìƒê´€ê³„ìˆ˜ëŠ” tê¸°ì˜ íŠ¹ì •(ê¸°ì¤€)ë³€ìˆ˜ xì˜ ê°’(ğ’™ğ’•)ê³¼ t+kê¸°ì— ê´€ì°°ëœ yê°’(ğ’šğ’•+ğ’Œ) ê°„ì˜ ìƒê´€ê´€ê³„ì˜ ì •ë„ë¥¼ ë‚˜íƒ€ëƒ„
# MAGIC - k=0ì¸ ê²½ìš° ì¦‰, ğœ¸ğŸì¸ ê²½ìš°ë¥¼ êµì°¨ìƒê´€ê³„ìˆ˜(cross correlation coefficient)ë¼ê³  í•˜ê³ , kâ‰ 0ì¸ ê²½ìš° ë¥¼ ì‹œì°¨ìƒê´€ê³„ìˆ˜(leads and lags correlationë¼ê³ ë„ í•¨
# MAGIC - êµì°¨ìƒê´€ê³„ìˆ˜ í•´ì„
# MAGIC   - ğœ¸ğŸ> 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(pro-cyclical:ê²½ê¸°ìˆœì‘)
# MAGIC   - ğœ¸ğŸ< 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(counter-cyclical:ê²½ê¸°ì—­í–‰)
# MAGIC   - ğœ¸ğŸ = 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ê²½ê¸°ì¤‘ë¦½ì 
# MAGIC - ì‹œì°¨ìƒê´€ê³„ìˆ˜ í•´ì„
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ ì–‘(+)ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì˜ í›„í–‰ì§€í‘œ
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ ìŒ(-)ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì˜ ì„ í–‰ì§€í‘œ
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ 0ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì™€ ë™í–‰ì§€í‘œ

# COMMAND ----------

# MAGIC %md
# MAGIC ## 0. CC ë¼ì´ë¸ŒëŸ¬ë¦¬ ìŠ¤í„°ë””

# COMMAND ----------

# MAGIC %md
# MAGIC ### ì˜ˆì œ1 : statsmodel CCF
# MAGIC - adjusted (=unbiased): ì°¸ì´ë©´ êµì°¨ ìƒê´€ì˜ ë¶„ëª¨ëŠ” nkì´ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ nì…ë‹ˆë‹¤.
# MAGIC   - í¸í–¥ë˜ì§€ ì•Šì€ ê²ƒì´ ì°¸ì´ë©´ ìê¸°ê³µë¶„ì‚°ì˜ ë¶„ëª¨ê°€ ì¡°ì •ë˜ì§€ë§Œ ìê¸°ìƒê´€ì€ í¸í–¥ë˜ì§€ ì•Šì€ ì¶”ì •ëŸ‰ì´ ì•„ë‹™ë‹ˆë‹¤.
# MAGIC - fft : Trueì´ë©´ FFT ì»¨ë³¼ë£¨ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸´ ì‹œê³„ì—´ì— ëŒ€í•´ ì„ í˜¸ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

# COMMAND ----------

#define data 
marketing = np.array([3, 4, 5, 5, 7, 9, 13, 15, 12, 10, 8, 8])
revenue = np.array([21, 19, 22, 24, 25, 29, 30, 34, 37, 40, 35, 30]) 

# COMMAND ----------

import statsmodels.api as sm

#calculate cross correlation
sm.tsa.stattools.ccf(marketing, revenue, adjusted=False)

# COMMAND ----------

#  ì‹œì°¨0ì—ì„œ êµì°¨ìƒê´€ì€ 0.771, ì‹œì°¨1ì—ì„œ êµì°¨ìƒê´€ì€ 0.462, ì‹œì°¨2ì—ì„œ êµì°¨ìƒê´€ì€ 0.194, ì‹œì°¨3ì—ì„œ êµì°¨ìƒê´€ì€ -0.061
#  íŠ¹ì • ì›”ì—ì„œ ë§ˆì¼€íŒ…ë¹„ìš©ì„ ì§€ì¶œí•˜ë©´ ë‹¤ìŒ 2ê°œì›”ë™ì•ˆì˜ ìˆ˜ìµì¦ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.

# COMMAND ----------

# MAGIC %md
# MAGIC ### ì˜ˆì œ2 : numpy.correlate

# COMMAND ----------

import numpy

myArray = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
myArray = numpy.array(myArray)
result = numpy.correlate(myArray, myArray, mode = 'full')
print(result)
print(result.size)
result = result[result.size // 2 :] # ì™„ì „íˆ ê²¹ì¹˜ëŠ” ì§€ì ì¸ ì¤‘ê°„ ì´í›„ë¶€í„° ë´ì•¼í•¨
print(result)

# COMMAND ----------

# MAGIC %md
# MAGIC ### ccfì™€ correlate ì™€ì˜ ì°¨ì´
# MAGIC - https://stackoverflow.com/questions/24616671/numpy-and-statsmodels-give-different-values-when-calculating-correlations-how-t
# MAGIC - ccfëŠ” np.correlate ë² ì´ìŠ¤ì´ì§€ë§Œ, í†µê³„ì ì˜ë¯¸ì—ì„œ ìƒê´€ê´€ê³„ë¥¼ ìœ„í•œ ì¶”ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•¨
# MAGIC - numpyê°€ í‘œì¤€í¸ì°¨ì˜ ê³±ìœ¼ë¡œ ê³µë¶„ì‚°ì„ ì •ê·œí™” í•˜ì§€ ì•ŠìŒ, ê°’ì´ ë„ˆë¬´ í¼
# MAGIC - ccfëŠ” í•©ì„±ê³±ì „ì— ì‹ í˜¸ì˜ í‰ê· ì„ ë¹¼ê³  ê²°ê³¼ë¥¼ ì²«ë²ˆì§¸ ì‹ í˜¸ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆ„ì–´ í†µê³„ì—ì„œì™€ ê°™ì€ ìƒê´€ê´€ê³„ ì •ì˜ì— ë„ë‹¬í•¨
# MAGIC - í†µê³„ ë° ì‹œê³„ì—´ ë¶„ì„ì—ì„œëŠ” êµì°¨ìƒê´€í•¨ìˆ˜ë¥¼ ì •ê·œí™”í•˜ì—¬ ì‹œê°„ì¢…ì† ìƒê´€ê³„ìˆ˜ë¥¼ ì–»ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤.
# MAGIC - ìê¸° ìƒê´€ì„ ìƒê´€ ê´€ê³„ë¡œ í•´ì„í•˜ë©´ í†µê³„ì  ì˜ì¡´ë„ ì˜ ì²™ë„ê°€ ì—†ëŠ” ì¸¡ì •ê°’ì´ ì œê³µ ë˜ê³  ì •ê·œí™”ëŠ” ì¶”ì •ëœ ìê¸° ìƒê´€ì˜ í†µê³„ì  ì†ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì— ì •ê·œí™”ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
# MAGIC - <ì•„ë˜ ì†ŒìŠ¤ì½”ë“œ ì°¸ê³ >
# MAGIC 
# MAGIC ```
# MAGIC def ccovf(x, y, unbiased=True, demean=True):
# MAGIC     n = len(x)
# MAGIC     if demean:
# MAGIC         xo = x - x.mean()
# MAGIC         yo = y - y.mean()
# MAGIC     else:
# MAGIC         xo = x
# MAGIC         yo = y
# MAGIC     if unbiased:
# MAGIC         xi = np.ones(n)
# MAGIC         d = np.correlate(xi, xi, 'full')
# MAGIC     else:
# MAGIC         d = n
# MAGIC     return (np.correlate(xo, yo, 'full') / d)[n - 1:]
# MAGIC 
# MAGIC def ccf(x, y, unbiased=True):
# MAGIC     cvf = ccovf(x, y, unbiased=unbiased, demean=True)
# MAGIC     return cvf / (np.std(x) * np.std(y))
# MAGIC ```

# COMMAND ----------

# ì¹´í…Œê³ ë¦¬ë³„ í”¼ì²˜ ë¶„ë¥˜ê¸°
def feature_classifier(data, feature):
    col_list = []
    for i in range(len(data.columns)):
        split_col = data.columns[i].split('_', maxsplit=1)[1]
        if split_col == feature:       
            col_list.append(data.columns[i])
        elif split_col == 'all_sales_usd' and feature == 'sales_usd' : #ì½œë ‰í„°ë¸”ë§Œ sales_usdì•ì— allì´ë¶™ì–´ì„œ ë”°ë¡œ ì²˜ë¦¬í•´ì¤Œ
            col_list.append('collectible_all_sales_usd')
        else :
            pass
    return col_list

# COMMAND ----------

avgusd = data[feature_classifier(data, 'average_usd')]
avgusd.head()

# COMMAND ----------

avgusd_game = avgusd['game_average_usd']
avgusd_game.head()

# COMMAND ----------

# raw
plt.plot(avgusd_game)

# COMMAND ----------

result = np.correlate(avgusd_game, avgusd_game, 'full')
print(result[result.size // 2 :])

# COMMAND ----------

# numpy.correlate
import numpy as np
from matplotlib import pyplot as plt
from statsmodels.tsa.stattools import ccf

#Calculate correlation using numpy.correlate
def corr(x,y):
    result = numpy.correlate(x, y, mode='full')
    return result[result.size//2:]

#Using numpy i get this
plt.plot(corr(avgusd_game,avgusd_game))

# COMMAND ----------

# statsmodel.ccf
plt.plot(ccf(avgusd_game, avgusd_game, adjusted=False))

# COMMAND ----------

# MAGIC %md
# MAGIC ### êµì°¨ìƒê´€ê³„ìˆ˜ ì‹œê°í™”
# MAGIC - https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xcorr.html
# MAGIC   - ì´ê±´ ì–´ë–»ê²Œ ì»¤ìŠ¤í…€ì„ ëª»í•˜ê² ë‹¤..

# COMMAND ----------

# numply.correlate
result = numpy.correlate(avgusd_game, avgusd_game, mode='full')
npcorr = result[result.size//2:]

nlags = len(npcorr)
leng = len(avgusd_game)

# /* Compute the Significance level */
conf_level = 2 / np.sqrt(nlags)
print('conf_level= ', conf_level)

# /* Draw Plot */
plt.figure(figsize=(30,10), dpi=80)
plt.hlines(0, xmin=0, xmax=leng, color='gray')  # 0 axis
plt.hlines(conf_level, xmin=0, xmax=leng, color='gray')
plt.hlines(-conf_level, xmin=0, xmax=leng, color='gray')

plt.bar(x=np.arange(len(npcorr)), height=npcorr, width=.3)
# plt.bar(x=avgusd_game.index, height=ccs, width=.3) # x ê¸¸ì´ëŠ” ê°™ì€ë°..  ì•ˆë¨..ccsê°’ê³¼ ì¸ë±ìŠ¤ì™€ ë§¤í•‘ì´ ì•ˆë˜ëŠ” ë“¯

# /* Decoration */
plt.title('Cross Correlation Plot <numpy.correlate>', fontsize=22)
plt.xlim(0,len(npcorr))
plt.show()

# COMMAND ----------

# ccf
ccs = ccf(avgusd_game, avgusd_game, adjusted=False)
nlags = len(ccs)
leng = len(avgusd_game)

# /* Compute the Significance level */
conf_level = 2 / np.sqrt(nlags)
print('conf_level= ', conf_level)

# /* Draw Plot */
plt.figure(figsize=(30,10), dpi=80)

plt.hlines(0, xmin=0, xmax=leng, color='gray')  # 0 axis
plt.hlines(conf_level, xmin=0, xmax=leng, color='gray')
plt.hlines(-conf_level, xmin=0, xmax=leng, color='gray')

plt.bar(x=np.arange(len(ccs)), height=ccs, width=.3)
# plt.bar(x=avgusd_game.index, height=ccs, width=.3) # ì•ˆë˜ë„¤..

# /* Decoration */
plt.title('Cross Correlation Plot <statsmodels.CCF>', fontsize=22)
plt.xlim(0,len(ccs))
plt.show()

# COMMAND ----------

# ì•½ 250ì¼ê¹Œì§€ ë‘ë³€ìˆ˜ ë“¤ì´ ì„œë¡œ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(pro-cyclical:ê²½ê¸°ìˆœì‘)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. CCF-CC êµì°¨ ìƒê´€ê³„ìˆ˜(Cross Correlation)
# MAGIC - avgusd ì¹´í…Œê³ ë¦¬ë³„ ë¹„êµ, ì‹œê°€ì´ì•¡ê³¼ ë¹„êµ
# MAGIC - ë³€ìˆ˜ê°„ ë™í–‰ì„±(comovement) ì¸¡ì •
# MAGIC - ê²½ê¸°ìˆœì‘ì (pro-cyclical) / ê²½ê¸°ì¤‘ë¦½ì (a-cyclical) / ê²½ê¸°ì—­í–‰ì (counter-cyclical)

# COMMAND ----------

# MAGIC %md
# MAGIC ### [í•¨ìˆ˜] êµì°¨ìƒê´€ê³„ìˆ˜ ì°¨íŠ¸ ìƒì„±ê¸°

# COMMAND ----------

# ccf ê³„ìˆ˜ ìƒì„±ê¸°
def ccf_data(data):
    ccfdata = ccf(data, data, adjusted=False)
    return ccfdata

# COMMAND ----------

## ccf ì°¨íŠ¸ ìƒì„±ê¸°
def ccfcc_plot(data, feature):
    # ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸í•¨ìˆ˜ í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    # ccf ê³„ìˆ˜ í•¨ìˆ˜ í˜¸ì¶œ
    for col in col_list:
        ccfdata = ccf_data(data[col])
    
        # /* Compute the Significance level */
        nlags = len(ccfdata)
        conf_level = 2 / np.sqrt(nlags)
#         print('conf_level= ', conf_level)
        print('êµì°¨ìƒê´€ê³„ìˆ˜ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  = ', min(np.where(ccfdata < 0)[0])-1)
        
        # /* Draw Plot */
        plt.figure(figsize=(30,10), dpi=80)

        plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis
        plt.hlines(conf_level, xmin=0, xmax=nlags, color='gray')
        plt.hlines(-conf_level, xmin=0, xmax=nlags, color='gray')

        plt.bar(x=np.arange(nlags), height=ccfdata, width=.3)
        # plt.bar(x=avgusd_game.index, height=ccs, width=.3) # ì•ˆë˜ë„¤..

        # /* Decoration */
        plt.title(f'Cross Correlation Plot <{col}>', fontsize=22)
        plt.xlim(0,nlags)
        plt.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ### ìê¸°êµì°¨ìƒê´€
# MAGIC - ì „ì²´ì¹´í…Œê³ ë¦¬ë³„ ì¸ë±ìŠ¤204~366 (ì•½6ê°œì›”ì—ì„œ 1ë…„ì£¼ê¸°)ê¹Œì§€ ë™í–‰ì„±ì´ ìˆìŒ
# MAGIC - acfì™€ ë™ì¼í•¨

# COMMAND ----------

 # ì „ì²´ ì¹´í…Œê³ ë¦¬- ìê¸°êµì°¨ìƒê´€ ì‹œê°í™”
ccfcc_plot(data, 'average_usd')

# COMMAND ----------

# acfì™€ ë™ì¼í•œë“¯, ë¹„êµí•´ë³´ì. pacfëŠ” 50%ì´í•˜ ê¸¸ì´ë¡œë§Œ ê°€ëŠ¥
# ì ˆë°˜ë§Œ ë´ë„ acfëŠ” ë¹„ìŠ·í•˜ë„¤.

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def autoCorrelationF1(data, feature):
    
        # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    for col in col_list:
        series = data[col]

        acf_array = acf(series.dropna(), alpha=0.05, nlags=850) 
        pacf_array = pacf(series.dropna(), alpha=0.05, nlags=850) # 50% ì´í•˜ ê¸¸ì´ê¹Œì§€ë§Œ ê°€ëŠ¥
        array_list = [acf_array, pacf_array]

        fig = make_subplots(rows=1, cols=2)

        for i in range(len(array_list)) :
            corr_array = array_list[i]
            lower_y = corr_array[1][:,0] - corr_array[0]
            upper_y = corr_array[1][:,1] - corr_array[0]
        
            [fig.add_scatter(x=(x,x), y=(0,corr_array[0][x]), mode='lines',line_color='#3f3f3f', row=1, col=i+1)
             for x in range(len(corr_array[0]))]

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=corr_array[0], mode='markers', marker_color='#1f77b4', marker_size=12, row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=upper_y, mode='lines', line_color='rgba(255,255,255,0)', row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=lower_y, mode='lines',fillcolor='rgba(32, 146, 230,0.3)',
                fill='tonexty', line_color='rgba(255,255,255,0)', row=1, col=i+1)

# 
            fig.update_traces(showlegend=False)
#             fig.update_xaxes(range=[-1,42])
            fig.update_yaxes(zerolinecolor='#000000')

        fig.update_layout(title= f'<b>[{col}] Autocorrelation (ACF)                                 [{col}] Partial Autocorrelation (PACF)<b>', 
                         title_x=0.5)
        fig.show()

# COMMAND ----------

autoCorrelationF1(data, 'average_usd')

# COMMAND ----------

# MAGIC %md
# MAGIC ### ìƒí˜¸êµì°¨ìƒê´€
# MAGIC - ì¹´í…Œê³ ë¦¬ê°€ ë„ˆë¬´ ë§ë‹¤. 4ê°œë§Œ êµì°¨í•´ì„œ ë³´ì collectible_avgusd, game_avgusd, all_avgusd, all_sales_usd
# MAGIC - ì¸ë±ìŠ¤265~315 (ì•½9ê°œì›”ì—ì„œ 10ê°œì›”ì£¼ê¸°)ê¹Œì§€ ë™í–‰ì„±ì´ ìˆìŒ

# COMMAND ----------

## ccf ì°¨íŠ¸ ìƒì„±ê¸°
def ccfcc_plot1(data):

    col_list = ['collectible_average_usd', 'game_average_usd','all_average_usd', 'all_sales_usd']
    x1col_list = []
    x2col_list = []
    ccfdata_list = []
    
    for i in range(len(col_list)-1):
        for j in range(1, len(col_list)):
            x1col_list.append(col_list[i])
            x2col_list.append(col_list[j])
            ccfdata_list.append(ccf(data[col_list[i]], data[col_list[j]], adjusted=False))
            
    plt.figure(figsize=(30,30), dpi=80)
    plt.suptitle("Cross Correlation Plot", fontsize=40)

    for i in range(len(ccfdata_list)):   
        ccfdata = ccfdata_list[i]
        # /* Compute the Significance level */
        nlags = len(ccfdata)
        conf_level = 2 / np.sqrt(nlags)

        # /* Draw Plot */
        plt.subplot(3, 3, i+1)   
        plt.title(f'<{x1col_list[i]} X {x2col_list[i]}, {min(np.where(ccfdata < 0)[0])-1} >', fontsize=22)
        plt.bar(x=np.arange(nlags), height=ccfdata, width=.3)
        plt.xlim(0,nlags)        

        plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis
        plt.hlines(conf_level, xmin=0, xmax=nlags, color='gray')
        plt.hlines(-conf_level, xmin=0, xmax=nlags, color='gray')
      
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

# COMMAND ----------

#  2~3ì—´ì´ ìƒí˜¸êµì°¨ìƒê´€ ê·¸ë˜í”„
ccfcc_plot1(data)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. CCF-LC ì‹œì°¨ ìƒê´€ê³„ìˆ˜(leads and lags correlation)
# MAGIC - ì‹œì°¨ ìƒí˜¸ ìƒê´€(TLCC) https://dive-into-ds.tistory.com/96
# MAGIC - ì„ í–‰ì (leading) / ë™í–‰ì (coincident) / í›„í–‰ì (lagging)

# COMMAND ----------

# # lag ë°ì´í„°í”„ë ˆì„ ìƒì„±ê¸°
# def lag_df(data, num):
#     col = data.columns
#     for i in range(1,num+1):
#         data[i] = data[col].shift(i)
#     return data

# COMMAND ----------

#  ì‹œì°¨ìƒê´€ê³„ìˆ˜ ê³„ì‚°í•¨ìˆ˜
def TLCC(X1, X2, lag):
    result=[]
    for i in range(lag):
        result.append(X1.corr(X2.shift(i)))
    return np.round(result, 4)
#     print(f'ì‹œì°¨ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ì€ lag = <{np.argmax(result)}>')

# COMMAND ----------

TLCC(data['game_average_usd'], data['collectible_average_usd'], 14)

# COMMAND ----------

TLCC(data['all_average_usd'], data['all_sales_usd'], 14)

# COMMAND ----------

TLCC(data['all_average_usd'], data['all_number_of_sales'], 100)

# COMMAND ----------

# MAGIC %md
# MAGIC ### avg_usdí”¼ì²˜, ì¹´í…Œê³ ë¦¬ë³„ ì‹œì°¨ìƒê´€ë¶„ì„

# COMMAND ----------

# ì¹´í…Œê³ ë¦¬ë³„ í”¼ì²˜ ë¶„ë¥˜ê¸°
def feature_classifier(data, feature):
    col_list = []
    for i in range(len(data.columns)):
        split_col = data.columns[i].split('_', maxsplit=1)[1]
        if split_col == feature:       
            col_list.append(data.columns[i])
        elif split_col == 'all_sales_usd' and feature == 'sales_usd' : #ì½œë ‰í„°ë¸”ë§Œ sales_usdì•ì— allì´ë¶™ì–´ì„œ ë”°ë¡œ ì²˜ë¦¬í•´ì¤Œ
            col_list.append('collectible_all_sales_usd')
        else :
            pass
    return col_list

# COMMAND ----------

# defiëŠ” 21-01-16ì— ë“¤ì–´ì˜´, ì´ 1704ì¤‘ã…‡ì— 400ê°œ, 1/6ë„ ì•ˆë˜ë¯€ë¡œ ì œì™¸í•œë‹¤
# data[['defi_average_usd']]['2021-01-15':]
avgusd_col_list = feature_classifier(data, 'average_usd')
avgusd_col_list.remove('defi_average_usd')
# avgusd_col_list.remove('all_average_usd')
print(len(avgusd_col_list), avgusd_col_list ) 

# COMMAND ----------

## TLCC ì°¨íŠ¸ ìƒì„±ê¸°
def TLCC_plot(data, col_list, nlag):

    x1col_list = []
    x2col_list = []
    TLCC_list = []

    for i in range(len(col_list)):
        for j in range(len(col_list)):
            if col_list[i] == col_list[j]:
                pass
            else:
                x1col_list.append(col_list[i])
                x2col_list.append(col_list[j])
                tlccdata =TLCC(data[col_list[i]], data[col_list[j]], nlag)
                TLCC_list.append(tlccdata)

    plt.figure(figsize=(30,40))
    plt.suptitle("TLCC Plot", fontsize=40)
    
    ncols = 3
    nrows = len(x1col_list)//3+1
    
    for i in range(len(TLCC_list)): 
        tlccdata = TLCC_list[i]
        plt.subplot(nrows, ncols, i+1)   
        plt.title(f'<{x1col_list[i]} X {x2col_list[i]}, {np.argmax(tlccdata)} >', fontsize=22)
        plt.plot(np.arange(len(tlccdata)), tlccdata)
        plt.xlim(-1,len(tlccdata)+1)        
        plt.vlines(np.argmax(tlccdata), ymin=min(tlccdata), ymax=max(tlccdata) , color='blue',linestyle='--',label='Peak synchrony')
#         plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

# COMMAND ----------

# ê·¸ë˜í”„ ë„ˆë¬´ ë§ë‹¤. ë³´ê¸° í˜ë“œë‹ˆê¹Œ ìƒëµí•˜ì
# TLCC_plot(data, avgusd_col_list, 14)

# COMMAND ----------

## TLCC table ìƒì„±ê¸°
def TLCC_table(data, col_list, nlag):

    x1col_list = []
    x2col_list = []
    TLCC_list = []
    TLCC_max_idx_list = []
    TLCC_max_list = []
    havetomoreX1 = []
    havetomoreX2 = []
    result = []

    for i in range(len(col_list)):
        for j in range(len(col_list)):
            if col_list[i] == col_list[j]:
                pass
            else:
                x1col_list.append(col_list[i])
                x2col_list.append(col_list[j])
                tlccdata = TLCC(data[col_list[i]], data[col_list[j]], nlag)
                TLCC_list.append(tlccdata)
                
                TLCC_max_idx= np.argmax(tlccdata)
                TLCC_max_idx_list.append(TLCC_max_idx)
                if TLCC_max_idx == nlag-1:
                    havetomoreX1.append(col_list[i])
                    havetomoreX2.append(col_list[j])
    
                TLCC_max = max(tlccdata)
                TLCC_max_list.append(TLCC_max)
                if TLCC_max >= 0.9:
                    result.append('*****')  # ì•„ì£¼ ë†’ì€ ìƒê´€ê´€ê³„
                elif TLCC_max >= 0.7 and TLCC_max < 0.9: 
                    result.append('****')# ë†’ì€ ìƒê´€ê´€ê³„ê°€ ìˆìŒ
                elif TLCC_max >= 0.4 and TLCC_max < 0.7:
                    result.append('***')# ë‹¤ì†Œ ìƒê´€ê´€ê³„ê°€ ìˆìŒ
                elif TLCC_max >= 0.2 and TLCC_max < 0.4:
                    result.append('**')# ì•½í•œ ìƒê´€ê´€ê³„
                elif TLCC_max < 0.2:
                    result.append('*')# ìƒê´€ê´€ê³„ ê±°ì˜ ì—†ìŒ
                else :
                    print('ë¶„ê¸° ì²´í¬ í•„ìš”')
                    
    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
    result_df = pd.DataFrame(data=list(zip(x1col_list, x2col_list, TLCC_max_idx_list, TLCC_max_list, result)), columns=['Lead(x1)', 'Lag(x2)', 'TLCC_max_idx', 'TLCC_max', 'result'])
    
    # max_tlcc_idxê°€ ìµœëŒ€lagì™€ ë™ì¼í•œ ì¹¼ëŸ¼ ë°˜í™˜                
    return havetomoreX1, havetomoreX2, result_df

# COMMAND ----------

# gameì´ í›„í–‰ì¸ ê²½ìš°ëŠ” ëª¨ë‘ ê°€ì¥ ë†’ì€ lagê°€ ê°’ì´ ë†’ë‹¤. ë” ì˜¬ë ¤ë³´ì
# utilityëŠ” ë‹¤ë¥¸ì¹´í…Œê³ ë¦¬ì™€ ê±°ì˜ ì‹œì°¨ìƒê´€ì„±ì´ ì—†ë‹¤.
havetomoreX1, havetomoreX2, result_df = TLCC_table(data, avgusd_col_list, 14)
result_df

# COMMAND ----------

print(havetomoreX1)
print(havetomoreX2)

# COMMAND ----------

for i in range(len(havetomoreX1)):
    tlccdata = TLCC(data[havetomoreX1[i]], data[havetomoreX2[i]], 150)
    print(havetomoreX1[i], havetomoreX2[i], np.argmax(tlccdata), np.round(max(tlccdata),4))

# COMMAND ----------

# ìµœëŒ€ lagê°’ìœ¼ë¡œ ë‹¤ì‹œ í™•ì¸í•´ë³´ì
havetomoreX1, havetomoreX2, result_df = TLCC_table(data, avgusd_col_list, 150)
result_df

# COMMAND ----------

# ì„ í–‰/í›„í–‰ì„ ìŒìœ¼ë¡œ ì¬ì •ë ¬í•˜ëŠ” í•¨ìˆ˜
def TLCC_table_filtered(data):
    result_x1x2_list = []
    result_after_x1 = []
    result_after_x2 = []
    for i in range(len(data)):
        result_x1x2_list.append(list(data.iloc[i, :2].values))

    for i in range(len(result_x1x2_list)):
        for j in range(len(result_x1x2_list)):
            if result_x1x2_list[i][0] == result_x1x2_list[j][1]  and result_x1x2_list[i][1] == result_x1x2_list[j][0]:
                result_after_x1.append(result_x1x2_list[i][0])
                result_after_x2.append(result_x1x2_list[i][1])
                result_after_x1.append(result_x1x2_list[j][0])
                result_after_x2.append(result_x1x2_list[j][1])


    result_x1x2_df = pd.DataFrame(data=list(zip(result_after_x1, result_after_x2)), columns=['after_x1','after_x2']) # 'x1->x2, x2->x1 ìŒë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
    result_x1x2_df.drop_duplicates(inplace=True) # ì¤‘ë³µ ì œê±°
    result_x1x2_df.reset_index(inplace=True) # ì¸ë±ìŠ¤ ë¦¬ì…‹
    
    after_x1 = []
    after_x2 = []
    TLCC_max_idx = []
    TLCC_max = []
    result = []
    print('<<TLCC ë°ì´í„°í”„ë ˆì„ì—ì„œ ìŒë³€ìˆ˜ìˆœìœ¼ë¡œ í•„í„°ë§>>')
    for i in range(len(result_x1x2_df)):
        xrow = data[data['Lead(x1)']==result_x1x2_df['after_x1'][i]]
        x1x2row = xrow[xrow['Lag(x2)']==result_x1x2_df['after_x2'][i]]
        after_x1.append(x1x2row.values[0][0])
        after_x2.append(x1x2row.values[0][1])
        TLCC_max_idx.append(x1x2row.values[0][2])
        TLCC_max.append(x1x2row.values[0][3])
        result.append(x1x2row.values[0][4])

    result_df_filtered = pd.DataFrame(data=list(zip(after_x1, after_x2, TLCC_max_idx, TLCC_max, result)), columns=['Lead(x1)', 'Lag(x2)', 'TLCC_max_idx', 'TLCC_max', 'result'])
    return result_df_filtered

# COMMAND ----------

# ì¬ì •ë ¬ëœ ë°ì´í„°í”„ë ˆì„, ì´ 30ê°œ í–‰
result_df_filtered = TLCC_table_filtered(result_df)
print(len(result_df_filtered))
result_df_filtered

# COMMAND ----------

# ë†’ì€ ìƒê´€ê´€ê³„ë§Œ ì¶”ë ¤ë³´ì(0.5 ì´ìƒ) 20ê°œ
good = result_df_filtered[result_df_filtered['TLCC_max'] >= 0.5] #  0.7ì´ìƒì´ 18ê°œ
print(len(good))
good
# all->art(22), collectible/metaverse->all(54), all->game(44), art<->collectible(0), art->game(32), metaverse->art(99), collectible->game(58), meta->collec(95), meta->game(143)

# COMMAND ----------

# ë³´í†µ/ë‚®ì€ ìƒê´€ê´€ê³„ë§Œ ì¶”ë ¤ë³´ì(0.5 ì´í•˜) 10ê°œ
bad = result_df_filtered[result_df_filtered['TLCC_max'] <= 0.5]
print(len(bad))
bad

# COMMAND ----------

# ìµœê·¼ í•œë‹¬ ì¤‘ì•™ê°’
data[avgusd_col_list][-30:].median()

# COMMAND ----------

# MAGIC %md
# MAGIC #### [ì‹¤í—˜ ê²°ê³¼] avg_usd ì¹´í…Œê³ ë¦¬ë³„ ì‹œì°¨ìƒê´€ë¶„ì„
# MAGIC ### ìƒê´€ê´€ê³„ê°€ ë‚®ì€ ì¼€ì´ìŠ¤
# MAGIC ####  - utility
# MAGIC ---
# MAGIC ### ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì¼€ì´ìŠ¤
# MAGIC ####  - ë™í–‰ : art-collectible/metaverse, collectible-metaverse, game-collectible
# MAGIC     - íŠ¹ì´ì‚¬í•­) art/collectible/metaverseëŠ” ëª¨ë‘ í‰ë‹¨ê°€ê°€ ë†’ì€ ì¹´í…Œê³ ë¦¬ì´ë‹¤. ì¶”ì •ìœ ì €êµ°ì¸ ì „ë¬¸íˆ¬ììë“¤ì€ ì¦‰ê° ë°˜ì‘ í•˜ë‚˜ë´„
# MAGIC       - artì‹œì¥ ê°€ê²©ê±°í’ˆì´ ë¹ ì§€ë©´ ë‹¤ë¥¸ ì‹œì¥ë„ ì˜í–¥ì„ ë°›ëŠ” ê²ƒì„
# MAGIC     - íŠ¹ì´ì‚¬í•­) game-collectibleì€ ìœ ì¼í•˜ê²Œ ì „ì²´ ìƒê´€ë¶„ì„ì—ë„ ë†’ì•˜ì—ˆëŠ”ë°..ì•„ë¬´ë˜ë„ ìœ ì €êµ°ì´ ê²¹ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ë¨(ì´ìœ ëŠ” ì•„ë˜ ê³„ì†)
# MAGIC ####  - ì§€ì—° : art/collectible/metaverse-game(32,58,143), metaverse-collectible(95)
# MAGIC     - íŠ¹ì´ì‚¬í•­) gameì´ ì„ í–‰ì¸ ì§€ì—°ì¼€ì´ìŠ¤ëŠ” ì—†ìŒ, ì¦‰ ê²Œì„í‰ê· ê°€ëŠ” ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ë¦¬ë“œí•˜ì§€ ì•ŠëŠ”ë‹¤.
# MAGIC       - ìœ ì…/í™œë™ì´ ì œì¼ ë§ì•„ nftë§ˆì¼“ì˜ ë¹„ì¤‘ì€ ë†’ìœ¼ë‚˜ "ë§ˆì¼“ì˜ ê°€ê²©í˜•ì„±"ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ê²ƒìœ¼ë¡œ ë³´ì•„, ìœ ì € ì˜¤ë””ì–¸ìŠ¤ íŠ¹ì§•ì´ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ ì¶”ì •. ë¼ì´íŠ¸ìœ ì €(ê²Œì„í•˜ë©° ëˆë²Œê¸°) vs í—¤ë¹„ìœ ì €(ì „ë¬¸íˆ¬ìì)
# MAGIC       - íˆ¬ìê´€ì ì—ì„œ ê²Œì„ì¹´í…Œê³ ë¦¬ëŠ” íˆ¬ìí•´ë´¤ì ëˆì´ ì•ˆë˜ê² ë„¤..
# MAGIC       - ê²Œì„ë§Œ ë‹¤ë¥¸ì¹´í…Œê³ ë¦¬ì™€ ë¶„ëª…í•˜ê²Œ ë‹¤ë¥¸ ê²½í–¥ì„ ë³´ì´ëŠ” ì´ìœ 
# MAGIC         - í‰ê· ê°€ ë²”ìœ„ ê°­ì´ ë§¤ìš° í¼, ìµœê·¼ í•œë‹¬ ì¤‘ì•™ê°’ ê²Œì„ 193 vs 3514, 1384, 2402
# MAGIC         - game í‰ê· ê°€ëŠ” ì—„ì²­ ì‘ì€ë° íŒë§¤ìˆ˜ ë§¤ìš° ë§ì•„ì„œ ì‹œì¥ê°€ì¹˜(sales usd) ë¹„ì¤‘ì´ ê½¤ ë†’ìŒ, 22ë…„1ì›” ì¤‘ì•™ê°’ ê²Œì„ 25% vs 14.2%, 55.4%, 5.3% 
# MAGIC ---
# MAGIC ### ì˜ë¬¸ì 1 : ì™œ ê·¹ë‹¨ì ìœ¼ë¡œ ë™í–‰ì„±(0) vs 1~5ë‹¬ì§€ì—°(34-149)ìœ¼ë¡œ ë‚˜ë‰ ê¹Œ? 
# MAGIC ####  - ë°˜ì‘ì´ ë„ˆë¬´ ëŠë¦¬ë‹¤. ì¼ì •ê¸°ê°„ì´ ë„˜ìœ¼ë©´ ë¬´ì˜ë¯¸í•œê²ƒ ì•„ë‹ê¹Œ..? ê·¸ê²ƒì„ ì•Œê¸° ìœ„í•´, allì„ ê°™ì´ ë´ì•¼ê² ë‹¤.
# MAGIC     - ë™í–‰ : all-collectible, art/game-all
# MAGIC     - ì§€ì—° : all-art/game(22, 44), collectible/metaverse-all(54, 54),
# MAGIC       - ì˜ë¬¸ì ) allì€ í¬ê´„ì¸ë° ì™œ art/gameë³´ë‹¤ ì„ í–‰í•˜ë‚˜? ì¬ê·€ì  ì˜í–¥ê´€ê³„??
# MAGIC       - ì˜ë¬¸ì ) ì‹œì¥ê°€ì¹˜ ë¹„ì¤‘ 14%ì¸ artê°€ allê³¼ ë™í–‰í•˜ê³ , ë‚˜ë¨¸ì§€ 2ê°œëŠ” 54ì¼ì´ë‹¤. ì™œì¼ê¹Œ? ì™¸ë¶€ ìš”ì¸ì´ ìˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •(ì–¸ë¡ ì´ìŠˆ)
# MAGIC     - ì¢…í•© : ì „ì²´ í‰ê· ê°€ì™€ ê°€ì¥ ë†’ì€ ì§€ì—°ì¸ 54ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì°¸ê³ í•  ìˆ˜ ìˆì„ê¹Œ? ì•„ë‹ˆë©´ ë§¤ìš° ê¸´ ì§€ì—°ë„ ìœ ì˜ë¯¸ í•˜ëŠ”ê±¸ê¹Œ?(ì¬ê·€ì  ì˜í–¥ê´€ê³„ë¡œ?) -
# MAGIC ---
# MAGIC ### ì˜ë¬¸ì 2 : ì„ í–‰/í›„í–‰ì˜ ê²°ê³¼ê°€ ê°™ê±°ë‚˜ ë‹¤ë¥¼ ê²½ìš° í•´ì„ì€ ì–´ë–»ê²Œ??
# MAGIC ####  - ìƒí˜¸ ë™í–‰ : ê±°ì˜ íŠ¹ì§•ì´ ë™ì¼í•˜ë‹¤ê³  ë´ë„ ë ë“¯
# MAGIC     - art<->collectible(0)
# MAGIC ####  - í¸ ì§€ì—°(í¸ë™í–‰ ìƒëµ) : aëŠ” bì— ë°”ë¡œ ë°˜ì‘ì´ ê°ˆ ì •ë„ë¡œ ì˜í–¥ì´ í¬ì§€ë§Œ, bëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ë‹¤?
# MAGIC     - metaverse -> art/collectible(99,55) -> game(32,58), meta->game(14),  collectible/metaverse->all(54), 3) all->art/game(22,44)
# MAGIC       - ì¸ê³¼ì— ë”°ë¼ì„œ ë©”íƒ€ë²„ìŠ¤ê°€ gameì— ì˜í–¥ì„ ì£¼ëŠ” ê±°ë¼ë©´ 143ì´ ìœ ì˜ë¯¸í•  ìˆ˜ë„ ìˆì„ ë“¯
# MAGIC       - allì´ art/gameì— ì¬ê·€ì ìœ¼ë¡œ ì˜í–¥ì„ ì£¼ëŠ” ê±°ë¼ë©´ allí”¼ì²˜ê°€ ìœ ì˜ë¯¸í•  ìˆ˜ë„ ìˆì„ ë“¯
# MAGIC ####  - ìƒí˜¸ ì§€ì—° : ì¦‰ì‹œ ë°˜ì‘ì„ ì¤„ì •ë„ì˜ ì˜í–¥ë ¥ì€ ì—†ëŠ”, ìƒëŒ€ì ìœ¼ë¡œ ì„œë¡œì—ê²Œ ë‚®ì€ ì˜í–¥ë ¥ì„ ê°€ì¡Œë‚˜?
# MAGIC     - ì—†ìŒ, ì´ ì¼€ì´ìŠ¤ê°€ í•©ë¦¬ì ì¸ ëª…ì œì¸ì§€ë„ ëª¨ë¥´ê² ìŒ í—·ê°ˆë¦¼
# MAGIC ---
# MAGIC ìœ„ ì˜ë¬¸ì„ í•´ì†Œí•˜ê¸° ìœ„í•œ ì¸ê³¼ê²€ì •ì´ í•„ìš”í•˜ë‹¤.
# MAGIC ---
# MAGIC #### ì¼€ì´ìŠ¤ ì…€ë ‰ì…˜
# MAGIC - ê³µì ë¶„ ê²€ì •ìš© ì¼€ì´ìŠ¤ : ì¼ë‹¨..ëŒ€í‘œ ì§€ì—°ì¼€ì´ìŠ¤ë¡œ collectible->game(59)ë¥¼ ê³µì ë¶„ ê²€ì¦í•´ë³´ì

# COMMAND ----------

# MAGIC %md
# MAGIC #### ëŒ€í‘œ ì¼€ì´ìŠ¤ ì‹œì°¨ìƒê´€ê³„ìˆ˜ ë¹„êµ í…Œì´ë¸”

# COMMAND ----------

avgusd_col_list

# COMMAND ----------

# ì›” ì¤‘ì•™ê°’ ì§‘ê³„ ë°ì´í„°
dataM_median = data.resample('M').median()
dataM_median.head()

# COMMAND ----------

# MAGIC %md
# MAGIC #### [í•¨ìˆ˜] ì‹œì°¨ìƒê´€ê³„ìˆ˜ ì°¨íŠ¸ ìƒì„±ê¸°

# COMMAND ----------

#  ì‹œì°¨ìƒê´€ê³„ìˆ˜ ê³„ì‚°í•¨ìˆ˜
def TLCC_comparison(X1, X2, start_lag, end_lag):
    result=[]
    laglist = []
    for i in range(start_lag, end_lag+1):
        result.append(X1.corr(X2.shift(i)))
        laglist.append(i)
    return laglist, np.round(result, 4)

# COMMAND ----------

# ì°¨íŠ¸ í•¨ìˆ˜
def TLCC_comparison_table(data, x1, x2, startlag, endlag): # ë°ì´í„°, ê¸°ì¤€ë³€ìˆ˜, ë¹„êµë³€ìˆ˜, startlag, endlag
    x2list = x2.copy()
    x2list.remove(x1)  # ì…ë ¥í•œ ë³€ìˆ˜ì—ì„œ ì‚­ì œë˜ê¸°ë•Œë¬¸ì— ì‚¬ì „ ì¹´í”¼í•„ìš”
    x2_list = [x1, *x2list]
    x1_list = []
    tlcc_list = []
    lag_var_list= []
    lvar_tlcc_list=[]
    sd_list = []
    rsd_list = []
    
    # x2ë³„ lag, tlccê°’ ë°›ì•„ì˜¤ê¸°
    for i in range(len(x2_list)): 
        x2data = data[x2_list[i]]
        lag_list,  result = TLCC_comparison(data[x1], x2data, startlag, endlag) 
        tlcc_list.append(result)
        sd_list.append(np.std(x2data))   # =stdev(ë²”ìœ„)
        rsd_list.append(np.std(x2data)/np.mean(x2data)*100)  # RSD = stdev(ë²”ìœ„)/average(ë²”ìœ„)*100, 
        # RSD(ìƒëŒ€í‘œì¤€í¸ì°¨) or CV(ë³€ë™ê³„ìˆ˜) : ë˜‘ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì–»ì€ ë°ì´í„°ë“¤ì´ ì„œë¡œ ì–¼ë§ˆë‚˜ ì˜ ì¼ì¹˜í•˜ëŠëƒ í•˜ëŠ” ì •ë„ë¥¼ ê°€ë¦¬í‚¤ëŠ” ì •ë°€ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„±ëŠ¥ê³„ìˆ˜, ê°’ì´ ì‘ì„ ìˆ˜ë¡ ì •ë°€í•˜ë‹¤.
        x1_list.append(x1)
        
    # ë°ì´í„°í”„ë ˆì„ìš© ë°ì´í„° ë§Œë“¤ê¸°
    temp = tlcc_list.copy()
    dfdata = list(zip(x1_list, x2_list, sd_list, rsd_list, *list(zip(*temp)))) # temp..arrayë¥¼ zipí• ìˆ˜ ìˆë„ë¡ í’€ì–´ì¤˜ì•¼í•¨..
    
    # ë°ì´í„°í”„ë ˆì„ìš© ì¹¼ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°
    column_list = ['X1ë³€ìˆ˜', 'X2ë³€ìˆ˜', 'X2í‘œì¤€í¸ì°¨', 'X2ìƒëŒ€í‘œì¤€í¸ì°¨', *lag_list]  

    result_df = pd.DataFrame(data=dfdata, columns= column_list,)

    return result_df

# COMMAND ----------

# íŒë‹¤ìŠ¤ ìŠ¤íƒ€ì¼ì˜ ì²œì˜ìë¦¬ êµ¬ë¶„ì€ 1.3 ë¶€í„° ì§€ì›í•¨
# pd.__version__ #  pip install --upgrade pandas==1.3  # import pandas as pd

# ë°ì´í„°í”„ë ˆì„ ë¹„ì£¼ì–¼ë¼ì´ì œì´ì…˜ í•¨ìˆ˜
def visualDF(dataframe):
#     pd.set_option('display.precision', 2) # ì†Œìˆ˜ì  ê¸€ë¡œë²Œ ì„¤ì •
    pd.set_option('display.float_format',  '{:.2f}'.format)
    dataframe = dataframe.style.bar(subset=['X2í‘œì¤€í¸ì°¨','X2ìƒëŒ€í‘œì¤€í¸ì°¨'])\
    .background_gradient(subset=[*result_df.columns[4:]], cmap='Blues', vmin = 0.5, vmax = 0.9)\
    .set_caption(f"<b><<< X1ë³€ìˆ˜({result_df['X1ë³€ìˆ˜'][0]})ê¸°ì¤€ X2ì˜ ì‹œì°¨ìƒê´€ê³„ìˆ˜'>>><b>")\
    .format(thousands=',')\
    .set_properties(
        **{'border': '1px black solid !important'})
    return dataframe

# COMMAND ----------

# ì›” ì¤‘ì•™ê°’ ê¸°ì¤€      # collectibleì— ëŒ€í•œ êµì°¨ì‹œì°¨ìƒê´€ë¶„ì„
print(f"<<<X1ê¸°ì¤€ X2ì˜ ë³€ë™í­ ë° ì‹œì°¨ìƒê´€ê³„ìˆ˜ í…Œì´ë¸”>>>")
result_df = TLCC_comparison_table(dataM_median, 'collectible_average_usd', avgusd_col_list, -6, 6)
result_df

# COMMAND ----------

# ì›”ì¤‘ì•™ê°’ ì „ì²´ê¸°ê°„
visualDF(result_df) 

# COMMAND ----------

# gmaeì´ ìƒê°ë³´ë‹¤ ìƒê´€ì´ ë‚®ê²Œ ë‚˜ì™”ë‹¤. gameë°ì´í„°ëŠ” 2017ë…„ ë°ì´í„° ì—†ìœ¼ë¯€ë¡œ, 2018ë…„ ì´í›„ ë°ì´í„°ë¡œ ë‹¤ì‹œ í•´ë³´ì

# COMMAND ----------

# ì›” ì¤‘ì•™ê°’ ê¸°ì¤€ "2018ë…„ ì´í›„ (gameë°ì´í„°ëŠ” 2017ë…„ ë°ì´í„° ì—†ìŒ)"
print(f"<<<X1ê¸°ì¤€ X2ì˜ ë³€ë™í­ ë° ì‹œì°¨ìƒê´€ê³„ìˆ˜ í…Œì´ë¸”>>>")
result_df = TLCC_comparison_table(dataM_median['2018':], 'collectible_average_usd', avgusd_col_list, -6, 6)
result_df

# COMMAND ----------

# ì›”ì¤‘ì•™ê°’ 2018ë…„ ì´í›„
visualDF(result_df)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [ê²°ë¡ ] ì›” ì¤‘ì•™ê°’ ê¸°ì¤€ ì‹œì°¨ìƒê´€ë¶„ì„(collectible_avgusd ê¸°ì¤€)
# MAGIC - 2018ë…„ì´í›„ ë°ì´í„°ë¡œ ë¶„ì„í•˜ë‹ˆ, ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìƒê´€ì„±ì´ ë†’ì•„ì¡Œë‹¤.(íŠ¹íˆ ê³¼ê±° ì‹œì°¨ê´€ë ¨)
# MAGIC - collectibleì˜ ìê¸°ìƒê´€ë„ëŠ” ë§¤ìš° ë†’ìœ¼ë‚˜ RSD ì •ë°€ë„ê°€ ë‚®ë‹¤.
# MAGIC - RSD(ìƒëŒ€í‘œì¤€í¸ì°¨)ëŠ” metaverseê°€ ìƒëŒ€ì ìœ¼ë¡œ ì •ë°€ë„ê°€ ë†’ê³ , artì™€ allì˜ ì •ë°€ë„ê°€ ë‚®ë‹¤.
# MAGIC - utilityëŠ” ìƒê´€ì„±ì´ ì—†ë‹¤.
# MAGIC - metaverseëŠ” yë³€ìˆ˜ê°€ ìŒìˆ˜ ì¼ ë•Œ ìƒê´€ì„±ì´ ë§¤ìš° ë†’ìœ¼ë¯€ë¡œ Xê°€ í›„í–‰í•œë‹¤. metaverse -> collectible  "ë§¤ìš° ëª…í™•"
# MAGIC - all, art, gameì€ yë³€ìˆ˜ê°€ ì–‘ìˆ˜ì¼ ë•Œ ìƒê´€ì„±ì´ ìŒìˆ˜ì¼ ë³´ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ë‹¤.
# MAGIC   - ê·¸ëŸ°ë° -2ìŒìˆ˜ì¼ë•Œë„ ë†’ì€ ê²ƒìœ¼ë¡œ ë³´ë‹¤ ìƒí˜¸ì§€ì—°ê´€ê³„ê°€ ìˆìœ¼ë©´ì„œ, ë™ì‹œì— Xì˜ ì„ í–‰ ì˜í–¥ë ¥ì´ ë” í¬ë‹¤. collectible <->> all/art/game(ë‹¨ ê²Œì„ì€ ë¹„êµì  ì§§ë‹¤)

# COMMAND ----------

# MAGIC %md
# MAGIC ### allì¹´í…Œê³ ë¦¬, í”¼ì²˜ë³„ ì‹œì°¨ìƒê´€ë¶„ì„

# COMMAND ----------

all_col_list = ['all_active_market_wallets','all_number_of_sales','all_average_usd','all_primary_sales','all_primary_sales_usd','all_sales_usd','all_secondary_sales','all_secondary_sales_usd','all_unique_buyers','all_unique_sellers']
print(len(all_col_list), all_col_list) # ì´ 10ê°œ ì¹´í…Œê³ ë¦¬

# COMMAND ----------

# ê·¸ë˜í”„ ë„ˆë¬´ ë§ë‹¤. ë³´ê¸° í˜ë“œë‹ˆê¹Œ ìƒëµí•˜ì
#  TLCC_plot(data, all_col_list, 14)

# COMMAND ----------

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# COMMAND ----------

# avgusdê°€ í›„í–‰ì¸ê²½ìš° lagê°’ì´ ê°€ì¥ ë†’ë‹¤. ë” ì˜¬ë ¤ë³´ì
havetomoreX1, havetomoreX2, result_df = TLCC_table(data, all_col_list, 14)
result_df

# COMMAND ----------

print(havetomoreX1)
print(havetomoreX2)

# COMMAND ----------

for i in range(len(havetomoreX1)):
    tlccdata = TLCC(data[havetomoreX1[i]], data[havetomoreX2[i]], 150)
    print(havetomoreX1[i], havetomoreX2[i], np.argmax(tlccdata), np.round(max(tlccdata),4))

# COMMAND ----------

# ìµœëŒ€ lagê°’ìœ¼ë¡œ ë‹¤ì‹œ í™•ì¸í•´ë³´ì
havetomoreX1, havetomoreX2, result_df = TLCC_table(data, all_col_list, 150)
result_df

# COMMAND ----------

# ì¬ì •ë ¬ëœ ë°ì´í„°í”„ë ˆì„, ì´ 90ê°œí–‰
result_df_filtered = TLCC_table_filtered(result_df)
print(len(result_df_filtered))
result_df_filtered

# COMMAND ----------

# ë†’ì€ ìƒê´€ê´€ê³„ë§Œ ì¶”ë ¤ë³´ì(0.75 ì´ìƒ) ì´ 93ê°œí–‰
good = result_df_filtered[result_df_filtered['TLCC_max'] >= 0.75]
print(len(good))
good
# ë™í–‰ì„±-ë™í–‰
# ì´ì§€ê°‘ìˆ˜<->ì´íŒë§¤ìˆ˜/1ì°¨íŒë§¤ìˆ˜/2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜,  ì´íŒë§¤ìˆ˜<->1ì°¨íŒë§¤ìˆ˜/2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜, 1ì°¨íŒë§¤ìˆ˜<->2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜, ì´ë§¤ì¶œ<->2ì°¨ë§¤ì¶œ
# 2ì°¨íŒë§¤ìˆ˜<->êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜, 2ì°¨ë§¤ì¶œ<->êµ¬ë§¤ììˆ˜, êµ¬ë§¤ììˆ˜<->íŒë§¤ììˆ˜

# ë™í–‰-ì§€ì—°
# ì´ì§€ê°‘ìˆ˜->ì´ë§¤ì¶œ(124), ì´íŒë§¤ìˆ˜->1ì°¨ë§¤ì¶œ(132)/ì´ë§¤ì¶œ(123), í‰ê· ê°€->1ì°¨ë§¤ì¶œ(98), ì´ë§¤ì¶œ->í‰ê· ê°€(98), 1ì°¨íŒë§¤ìˆ˜->1ì°¨ë§¤ì¶œ(119)/ì´ë§¤ì¶œ(117)/íŒë§¤ììˆ˜(143), ì´ë§¤ì¶œ->1ì°¨ë§¤ì¶œ(98), 2ì°¨ë§¤ì¶œ->1ì°¨ë§¤ì¶œ(118)
# 2ì°¨íŒë§¤ìˆ˜->ì´ë§¤ì¶œ(127), êµ¬ë§¤ììˆ˜->ì´ë§¤ì¶œ(123), íŒë§¤ììˆ˜->ì´ë§¤ì¶œ(130), 2ì°¨íŒë§¤ìˆ˜->2ì°¨ë§¤ì¶œ(125)
# íŒë§¤ììˆ˜->2ì°¨ë§¤ì¶œ(127)

# ì§€ì—°-ì§€ì—°
#  ì´ì§€ê°‘ìˆ˜<->í‰í‰ê· ê°€(100<->70),1ì°¨ë§¤ì¶œ(132<->56)  , ì´íŒë§¤ìˆ˜<->í‰ê· ê°€(100,66), í‰ê· ê°€<->1ì°¨íŒë§¤ìˆ˜(66,100),2ì°¨íŒë§¤ìˆ˜(65, 100),2ì°¨ë§¤ì¶œ(33,98),êµ¬ë§¤ììˆ˜(71,100),íŒë§¤ììˆ˜(67,100),  1ì°¨ë§¤ì¶œ<->2ì°¨íŒë§¤ìˆ˜(56,134)
# 1ì°¨ë§¤ì¶œ<->êµ¬ë§¤ììˆ˜(56,132),íŒë§¤ììˆ˜(56,135)

# COMMAND ----------

# ë³´í†µ/ë‚®ì€ ìƒê´€ê´€ê³„ë§Œ ì¶”ë ¤ë³´ì(0.75 ì´í•˜) ì—†ìŒ 7ê°œ
bad = result_df_filtered[result_df_filtered['TLCC_max'] <= 0.75]
print(len(bad))
bad

# COMMAND ----------

# MAGIC %md
# MAGIC #### [ì‹¤í—˜ ê²°ê³¼] allì¹´í…Œê³ ë¦¬ í”¼ì²˜ë³„ ì‹œì°¨ìƒê´€ë¶„ì„ 
# MAGIC 
# MAGIC ### ìƒê´€ê´€ê³„ê°€ ë‚®ì€ ì¼€ì´ìŠ¤
# MAGIC ####  - ëŒ€ì²´ë¡œ ë†’ë‹¤. 1ì°¨ë§¤ì¶œì´ ë¦¬ë“œí•˜ëŠ” ê²½ìš°ê°€ ìƒëŒ€ì ìœ¼ë¡œ 0.6~7ë¡œ ë‚®ì€í¸
# MAGIC ---
# MAGIC ### ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì¼€ì´ìŠ¤
# MAGIC - í•­ëª©ì´ ë§ì•„ ë¶„ì„ì´ ì–´ë µë‹¤. êµ¬ì²´ì ì¸ ê³¼ì œì— ë§ì¶° ë¶„ì„í•˜ëŠ”ê²Œ ì¢‹ì„ ë“¯
# MAGIC - **í‰ê· ê°€ ê¸°ì¤€) ì´ì§€ê°‘ìˆ˜/ì´íŒë§¤ìˆ˜/1ì°¨íŒë§¤ìˆ˜/2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜ëŠ” í‰ê· ê°€ì™€ ëŒ€ì²´ë¡œ 2~3ë‹¬ì˜ ìƒí˜¸ì§€ì—°ê´€ê³„ì´ê³ , ì´ë§¤ì¶œê³¼ í‰ê· ê°€ ê·¸ë¦¬ê³  1ì°¨ë§¤ì¶œì€ ì•½ 3ë‹¬ì˜ í¸ì§€ì—°ê´€ê³„ë¥¼ ê°–ëŠ”ë‹¤.**
# MAGIC - **íŠ¹ì´ì‚¬í•­) ì‹œì°¨ì§€ì—°ì˜ ê²½ìš°, ìœ„ í‰ê· ê°€ í”¼ì²˜ë³„ë¶„ì„ì™€ ë™ì¼í•˜ê±°ë‚˜ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ í¸ì´ê³ (33~143), "ìƒí˜¸ì§€ì—°ê´€ê³„" ë§ë‹¤.**
# MAGIC - **ì˜ë¬¸ì  ) "í‰ê· ê°€ì™€ êµ¬ë§¤ììˆ˜ì˜ ì§€ì—°ê´€ê³„ê°€ 2~3ë‹¬ì´ë©´ ìƒê°ë³´ë‹¤ ë„ˆë¬´ ê¸¸ë‹¤"**  
# MAGIC 
# MAGIC #### ìƒí˜¸ ë™í–‰
# MAGIC - ì´ì§€ê°‘ìˆ˜<->ì´íŒë§¤ìˆ˜/1ì°¨íŒë§¤ìˆ˜/2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜,  ì´íŒë§¤ìˆ˜<->1ì°¨íŒë§¤ìˆ˜/2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜, 
# MAGIC - 1ì°¨íŒë§¤ìˆ˜<->2ì°¨íŒë§¤ìˆ˜/2ì°¨ë§¤ì¶œ/êµ¬ë§¤ììˆ˜, ì´ë§¤ì¶œ<->2ì°¨ë§¤ì¶œ, 2ì°¨íŒë§¤ìˆ˜<->êµ¬ë§¤ììˆ˜/íŒë§¤ììˆ˜, 2ì°¨ë§¤ì¶œ<->êµ¬ë§¤ììˆ˜, êµ¬ë§¤ììˆ˜<->íŒë§¤ììˆ˜ 
# MAGIC 
# MAGIC #### í¸ ì§€ì—°(í¸ë™í–‰ ìƒëµ)
# MAGIC - ì´ì§€ê°‘ìˆ˜->ì´ë§¤ì¶œ(124), ì´íŒë§¤ìˆ˜->1ì°¨ë§¤ì¶œ(132)/ì´ë§¤ì¶œ(123), í‰ê· ê°€->1ì°¨ë§¤ì¶œ(98), ì´ë§¤ì¶œ->í‰ê· ê°€(98), 1ì°¨íŒë§¤ìˆ˜->1ì°¨ë§¤ì¶œ(119)/ì´ë§¤ì¶œ(117)/íŒë§¤ììˆ˜(143)
# MAGIC - ì´ë§¤ì¶œ->1ì°¨ë§¤ì¶œ(98), 2ì°¨ë§¤ì¶œ->1ì°¨ë§¤ì¶œ(118), 2ì°¨íŒë§¤ìˆ˜->ì´ë§¤ì¶œ(127), êµ¬ë§¤ììˆ˜->ì´ë§¤ì¶œ(123), íŒë§¤ììˆ˜->ì´ë§¤ì¶œ(130), 2ì°¨íŒë§¤ìˆ˜->2ì°¨ë§¤ì¶œ(125), íŒë§¤ììˆ˜->2ì°¨ë§¤ì¶œ(127)
# MAGIC 
# MAGIC #### ìƒí˜¸ ì§€ì—°
# MAGIC - ì´ì§€ê°‘ìˆ˜<->í‰ê· ê°€(100,70)/1ì°¨ë§¤ì¶œ(132,56), ì´íŒë§¤ìˆ˜<->í‰ê· ê°€(100,66), í‰ê· ê°€<->1ì°¨íŒë§¤ìˆ˜(66,100)/2ì°¨íŒë§¤ìˆ˜(65, 100)/2ì°¨ë§¤ì¶œ(33,98)/êµ¬ë§¤ììˆ˜(71,100)/íŒë§¤ììˆ˜(67,100)
# MAGIC - 1ì°¨ë§¤ì¶œ<->2ì°¨íŒë§¤ìˆ˜(56,134), 1ì°¨ë§¤ì¶œ<->êµ¬ë§¤ììˆ˜(56,132),íŒë§¤ììˆ˜(56,135)
# MAGIC 
# MAGIC ---
# MAGIC #### ì¼€ì´ìŠ¤ ì…€ë ‰ì…˜
# MAGIC - ê³µì ë¶„ ê²€ì •ìš© ì¼€ì´ìŠ¤ : ì¼ë‹¨..ëŒ€í‘œ ì§€ì—°ì¼€ì´ìŠ¤ë¡œ avgusd->buyer(71)ì„ ê³µì ë¶„ ê²€ì¦í•´ë³´ì(avg_usdë¥¼ ì˜ˆì¸¡í–ˆìœ¼ë‹ˆê¹Œ..)**

# COMMAND ----------

# MAGIC %md
# MAGIC #### ëŒ€í‘œ ì¼€ì´ìŠ¤ ì‹œì°¨ìƒê´€ê³„ìˆ˜ ë¹„êµ í…Œì´ë¸”

# COMMAND ----------

all_col_list

# COMMAND ----------

# ì›” ì¤‘ì•™ê°’ ì§‘ê³„ ë°ì´í„°
dataM_median.head()

# COMMAND ----------

# ì›” ì¤‘ì•™ê°’ ê¸°ì¤€
print(f"<<<X1ê¸°ì¤€ X2ì˜ ë³€ë™í­ ë° ì‹œì°¨ìƒê´€ê³„ìˆ˜ í…Œì´ë¸”>>>")
result_df = TLCC_comparison_table(dataM_median, 'all_average_usd', all_col_list, -6, 6)
result_df

# COMMAND ----------

# ì›”ì¤‘ì•™ê°’ ê¸°ì¤€
visualDF(result_df)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [ê²°ë¡ ] ì›” ì¤‘ì•™ê°’ ê¸°ì¤€ ì‹œì°¨ìƒê´€ë¶„ì„(all_avgusd ê¸°ì¤€)
# MAGIC - all_avgusdì˜ ìê¸°ìƒì€ í•œë‹¬ ì „í›„ê°€ ë§¤ìš° ë†’ìŒ
# MAGIC - RSDëŠ” 1ì°¨íŒë§¤ìˆ˜ì˜ ì •ë°€ë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€í¸ì´ë‹¤.
# MAGIC - ëŒ€ì²´ë¡œ ìƒê´€ì„±ì´ ë§¤ìš° ë†’ì€ë° X2ê°€ ìŒìˆ˜ì¼ ë•Œ ìƒê´€ì„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ë” ë†’ìœ¼ë¯€ë¡œ X1ê°€ í›„í–‰í•œë‹¤. X2 -> í‰ê· ê°€
# MAGIC - íŠ¹ì´ì ì€ ì¼ë¶€(ê°€ê²©ë¥˜)ë¥¼ ì œì™¸í•˜ê³  2ë‹¬ ë‚´ì™¸ë¶€í„° ìƒê´€ì„±ì´ ë†’ì•„ì§„ë‹¤ëŠ” ê²ƒ. ì¦‰ ê°€ê²©ë¥˜ëŠ” ìƒí˜¸ ë™í–‰í•˜ê³  ê·¸ì™¸ëŠ” ì•½2ë‹¬ì˜ ì§€ì—° ê´€ê³„ê°€ ìˆë‹¤.

# COMMAND ----------

# MAGIC %md
# MAGIC ### ì‹œê°í™”(pass)
# MAGIC - ì˜ˆì œ í•´ì„ì„ ëª»í•˜ê² ì–´ì„œ pass

# COMMAND ----------

# MAGIC %md 
# MAGIC #### ì˜ˆì œ1: line
# MAGIC - ì–´ë–»ê²Œ í•´ì„ì„ í•´ì•¼í• ì§€ ëª¨ë¥´ê² ë‹¤

# COMMAND ----------

def crosscorr(datax1, datax2, lag=0, wrap=False):
# """ Lag-N cross correlation. 
# Shifted data filled with NaNs 

# Parameters
# ----------
# lag : int, default 0
# datax, datay : pandas.Series objects of equal length
# wrap : NaN ì±„ìš°ëŠ” ê²ƒ. shift í•˜ë©´ì„œ ì‚¬ë¼ì§„ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ì±„ìš°ê¸°. ê°’ì´ ìˆœí™˜ë˜ê²Œ ëœë‹¤. wrap=False ì´ë©´ NaNì€ dropí•˜ê³  correlation êµ¬í•œë‹¤.
# Returns
# ----------
# crosscorr : float
# """
    if wrap:
        shiftedx2 = datax2.shift(lag)
        shiftedx2.iloc[:lag] = datax2.iloc[-lag:].values
        return datax1.corr(shiftedx2)
    else: 
        return datax1.corr(datay.shift(lag))

# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. offset ì–‘ìˆ˜ì´ë¯€ë¡œ s2ê°€ ì„ í–‰í•œë‹¤? 59ì¼ì°¨?
s1 = data['game_average_usd']
s2 = data['collectible_average_usd']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. offset ì–‘ìˆ˜ì´ë¯€ë¡œ s2ê°€ ì„ í–‰í•œë‹¤? ì´ê±´ ì´ìƒí•œë°.. í‰ê· ê°€ë³´ë‹¤ ë§ˆì¼“ì´ ì„ í–‰í•œë‹¤ê³ ?. ì„¸ì¼ì¦ˆë‘ ë¹„êµí•´ë´ì•¼í•˜ë‚˜.
s1 = data['all_average_usd']
s2 = data['all_sales_usd']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. ëª¨ë¥´ê² ë‹¤.
s1 = data['all_average_usd']
s2 = data['all_number_of_sales']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------

# MAGIC %md 
# MAGIC #### ì˜ˆì œ2: heatmap
# MAGIC - ì´ê²ƒë„ ë­˜ì–´ë–»ê²Œ ë´ì•¼í• ì§€ ëª¨ë¥´ê² ë‹¤.

# COMMAND ----------

data.shape[0]//20

# COMMAND ----------

no_splits = 30
samples_per_split = data.shape[0]//no_splits
rss=[]

for t in range(0, no_splits):
    d1 = data['game_average_usd'].iloc[(t)*samples_per_split:(t+1)*samples_per_split]
    d2 = data['collectible_average_usd'].iloc[(t)*samples_per_split:(t+1)*samples_per_split]
    rs = [crosscorr(d1,d2, lag) for lag in range(-300,300)]
    rss.append(rs)
rss = pd.DataFrame(rss)
f,ax = plt.subplots(figsize=(30,10))
sb.heatmap(rss, cmap='RdBu_r',ax=ax)
ax.set(title=f'Windowed Time Lagged Cross Correlation', xlabel='Offset',ylabel='Window epochs')
# ax.set_xticks([0, 50, 100, 151, 201, 251, 301])
# ax.set_xticklabels([-150, -100, -50, 0, 50, 100, 150]);

# Rolling window time lagged cross correlation
window_size = 300 #samples
t_start = 0
t_end = t_start + window_size
step_size = 30
rss=[]
while t_end < 1704:
    d1 = data['game_average_usd'].iloc[t_start:t_end]
    d2 = data['collectible_average_usd'].iloc[t_start:t_end]
    rs = [crosscorr(d1,d2, lag, wrap=False) for lag in range(-300,300)]
    rss.append(rs)
    t_start = t_start + step_size
    t_end = t_end + step_size
rss = pd.DataFrame(rss)

f,ax = plt.subplots(figsize=(30,10))
sb.heatmap(rss,cmap='RdBu_r',ax=ax)
ax.set(title=f'Rolling Windowed Time Lagged Cross Correlation',xlabel='Offset',ylabel='Epochs')
# ax.set_xticks([0, 50, 100, 151, 201, 251, 301])
# ax.set_xticklabels([-150, -100, -50, 0, 50, 100, 150]);

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. ê³µì ë¶„ ê²€ì •(Cointegration Test)
# MAGIC ####- ê°œë… : ì‹œê³„ì—´ Yì™€ ì‹œê³„ì—´ X ëª¨ë‘ <<ì¼ì°¨ ì°¨ë¶„ì´ ì•ˆì •ì ì¸ ì‹œê³„ì—´(I(1)ê³¼ì •, 1ì°¨ì ë¶„ê³¼ì •)ì´ê³ >> ë‘ì‹œê³„ì—´ ì‚¬ì´ì— ì•ˆì •ì ì¸ ì„ í˜•ê²°í•©ì´ ì¡´ì¬í•œë‹¤ë©´ ë‘ì‹œê³„ì—´ê°„ì— ê³µì ë¶„ì´ ì¡´ì¬í•œë‹¤ê³  ì •ì˜í•œë‹¤.
# MAGIC   - ì¦‰ Xì™€ Yê°€ ê³µì ë¶„ê´€ê³„ì— ìˆë‹¤ë©´ ì•„ë¬´ë¦¬ Xì™€ Yê°€ ë¶ˆì•ˆì •ì  í™•ë¥ ë³€ìˆ˜(I(1))ë¼ê³  í•´ë„ ë‘ë³€ìˆ˜ì— ëŒ€í•œ íšŒê·€ì‹ì„ ì„¸ì›Œë„ í—ˆêµ¬ì ì¸ íšŒê·€í˜„ìƒì´ ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ”ë‹¤.
# MAGIC     - ê³µì ë¶„ ê´€ê³„ëŠ”, ë‹¨ê¸°ì ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ íŒ¨í„´ì„ ë³´ì´ì§€ë§Œ ì¥ê¸°ì ìœ¼ë¡œ ë³¼ ë•Œ ì¼ì •í•œ ê´€ê³„ê°€ ìˆìŒì„ ì˜ë¯¸í•¨, 
# MAGIC 
# MAGIC ####- ê²€ì • ë°©ë²• : ëŒ€í‘œì ìœ¼ë¡œ ìš”í•œìŠ¨ ê²€ì •ì„ ë§ì´ í•¨
# MAGIC   - (ë‹¨ë³€ëŸ‰) engel & granget ê²€ì • : ADFë‹¨ìœ„ê·¼ê²€ì • ì•„ì´ë””ì–´
# MAGIC   - (ë‹¤ë³€ëŸ‰) johansen ê²€ì • : ADFë‹¨ìœ„ê·¼ê²€ì •ì„ ë‹¤ë³€ëŸ‰ì˜ ê²½ìš°ë¡œ í™•ì¥í•˜ì—¬ ìµœìš°ì¶”ì •ì„ í†µí•´ ê²€ì • ìˆ˜í–‰

# COMMAND ----------

# MAGIC %md
# MAGIC ### (ë‹¨ë³€ëŸ‰)Engle-Granger 2step OLS Test
# MAGIC - statsmodels.coint ëŠ” engle-granger ê¸°ë°˜, [signatrue](https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.coint.html)
# MAGIC - íšŒê·€ë¶„ì„ ê²°ê³¼ì˜ ì”ì°¨í•­ì— ëŒ€í•´ ê²€ì •
# MAGIC   - OLSì¶”ì •ëŸ‰ì„ ì´ìš©í•˜ì—¬ íšŒê·€ëª¨í˜• Y=bX+zì„ ì¶”ì •í•˜ì—¬ ì”ì°¨í•­ zhatì„ êµ¬í•œë‹¤. ê·¸ë¦¬ê³  ì”ì°¨í•­ zhatì— ëŒ€í•œ DFê²€ì •ì„ ìˆ˜í–‰í•œë‹¤.
# MAGIC   - ì¼ë°˜ DFì„ê³„ê°’ê³¼ëŠ” ë‹¤ë¥¸ ì„ê³„ê°‘ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.('ê³µì ë¶„ ê²€ì • ì„ê³„ê°’ ë¶„í¬í‘œ')
# MAGIC 
# MAGIC - ê·€ë¬´ê°€ì„¤ : ë¹„ì •ìƒ ì‹œê³„ì—´ ê°„ì˜ ì¡°í•©ì— ë”°ë¥¸ ì˜¤ì°¨í•­ì— ë‹¨ìœ„ê·¼ì´ ì¡´ì¬í•œë‹¤. ì¦‰, ì„œë¡œ ê³µì ë¶„ ê´€ê³„ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
# MAGIC   - p-valueê°’ì´ 5%ë³´ë‹¤ ì‘ì„ ë•Œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì—¬ ê³µì ë¶„ê´€ê³„ê°€ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
# MAGIC 
# MAGIC - ì•µê¸€&ê·¸ë ˆì¸ì € ê²€ì •ì˜ í•œê³„ë¡œ ì¼ë°˜ì ìœ¼ë¡œ ìš”í•œìŠ¨ì„ ë§ì´ ì‚¬ìš©í•œë‹¤.
# MAGIC   - ì‹œê³„ì—´ ì‚¬ì´ì— 1ê°œì˜ ê³µì ë¶„ ê´€ê³„ë§Œ íŒë³„í•  ìˆ˜ ìˆìŒ, ì¦‰3ê°œ ì´ìƒì˜ ì‹œê³„ì—´ì‚¬ì´ì˜ ê³µì ë¶„ ê²€ì • ë¶ˆê°€
# MAGIC   - íšŒê·€ ëª¨í˜•ìœ¼ë¡œ ì¥ê¸°ê· í˜•ê´€ê³„ë¥¼ íŒë‹¨í•  ë•Œ í‘œë³¸ì˜ í¬ê¸°ê°€ ë¬´í•œí•˜ì§€ ì•Šìœ¼ë©´ ì¢…ì†ë³€ìˆ˜ë¡œ ì–´ë–¤ ì‹œê³„ì—´ì„ ì„ íƒí•˜ëŠ”ì§€ì— ë”°ë¼ ê²€ì •ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ë¬¸ì œê°€ ìˆê³ , ì‹œê³„ì—´ ìˆ˜ê°€ ì¦ê°€í•˜ë©´ ë” ì‹¬í•´ì§
# MAGIC   
# MAGIC - [ì•µê¸€&ê·¸ë ˆì¸ì € ê³µì ë¶„ ê²€ì • ì˜ˆì œ1](https://mkjjo.github.io/finance/2019/01/25/pair_trading.html)
# MAGIC - [ì•µê¸€&ê·¸ë ˆì¸ì € ê³µì ë¶„ ê²€ì • ì˜ˆì œ2](https://lsjsj92.tistory.com/584)

# COMMAND ----------

import statsmodels.tsa.stattools as ts
# pd.set_option('display.precision', 2) 
# pd.options.display.float_format = '{:.2f}'.format

# COMMAND ----------

# ê³µì ë¶„ ê´€ê³„ ì‹œê°í™” (ë‘ë³€ìˆ˜ê°„ì˜ ë¹„ìœ¨ì´ í‰ê· ì„ ì¤‘ì‹¬ìœ¼ë¡œë‹¬ë¼ì§€ëŠ”ì§€ í™•ì¸) -> ì–´ë–»ê²Œ ë³´ëŠ”ê±°ì§€? ì¥ê¸°ì ìœ¼ë¡œ í¸ì°¨ê°€ ì ì–´ì§€ë©´ ì¥ê¸°ì  ê´€ê³„ê°€ ìˆë‹¤??
import statsmodels.tsa.stattools as ts
x1 = data['collectible_average_usd']['2018':]
x2 = data['game_average_usd']['2018':]

# ë””í´íŠ¸ : rawë°ì´í„°(ë¡œê·¸ë³€í™˜/ìŠ¤ì¼€ì¼ë§ë“± ì •ê·œí™”í•˜ë©´ ì•ˆë¨, íŠ¹ì§• ì‚¬ë¼ì§), augmented engle&granger(default), maxlag(none), trend='c'
score, pvalue, _ = ts.coint(x1,x2)
print(f'ì¶”ì„¸ ìƒìˆ˜ only //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='ct')
print(f'ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸° //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='ctt')
print(f'ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸°(2ì°¨) //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='nc')
print(f'ì¶”ì„¸ ì—†ìŒ //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')

(x2/x1).plot(figsize=(30,10))
plt.axhline((x2/x1).mean(), color='red', linestyle='--')
plt.xlabel('Time')
plt.title('collectible / game Ratio')
plt.legend(['collectible / game Ratio', 'Mean'])
plt.show()

# COMMAND ----------

# MAGIC %md
# MAGIC #### [EGê²°ê³¼] collectible avgusd vs game avgusd
# MAGIC - ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸°(2ì°¨) ì¼€ì´ìŠ¤ : p-valueê°’ì´ 0.85ë¡œ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•˜ì—¬ **ê³µì ë¶„ê´€ê³„ ì—†ìŒ, VARëª¨í˜• ì±„íƒ**
# MAGIC - ì¶”ì„¸ ì—†ìŒ ì¼€ì´ìŠ¤ : p-valueê°’ì´ 0.33ë¡œ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•˜ì—¬ **ê³µì ë¶„ê´€ê³„ ì—†ìŒ, VARëª¨í˜• ì±„íƒ**

# COMMAND ----------

# ê³µì ë¶„ ê´€ê³„ ì‹œê°í™” -> ê´€ê³„ê°€ ìˆëŠ”ê±°ì•¼ë­ì•¼?
import statsmodels.tsa.stattools as ts
x1 = data['all_average_usd']
x2 = data['all_unique_buyers']

# ë””í´íŠ¸ : rawë°ì´í„°(ë¡œê·¸ë³€í™˜/ìŠ¤ì¼€ì¼ë§ë“± ì •ê·œí™”í•˜ë©´ ì•ˆë¨, íŠ¹ì§• ì‚¬ë¼ì§), augmented engle&granger(default), maxlag(none), trend='c'
score, pvalue, _ = ts.coint(x1,x2)
print(f'ì¶”ì„¸ ìƒìˆ˜ only //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='ct')
print(f'ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸° //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='ctt')
print(f'ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸°(2ì°¨) //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')
score, pvalue, _ = ts.coint(x1,x2, trend='nc')
print(f'ì¶”ì„¸ ì—†ìŒ //  ADF score={np.round(score, 4)} // coint test p-value={np.round(pvalue, 4)}')

(x2/x1).plot(figsize=(30,10))
plt.axhline((x2/x1).mean(), color='red', linestyle='--')
plt.xlabel('Time')
plt.title('all_buyers / all_avg_usd Ratio')
plt.legend(['all_buyers / all_avg_usd Ratio', 'Mean'])
plt.show()

# COMMAND ----------

# MAGIC %md
# MAGIC #### [EGê²°ê³¼] all_avgusd vs all_buyers
# MAGIC - ì¶”ì„¸ ìƒìˆ˜&ê¸°ìš¸ê¸°(2ì°¨) ì¼€ì´ìŠ¤ : p-valueê°’ì´ 0.55ë¡œ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•˜ì—¬ **ê³µì ë¶„ê´€ê³„ ì—†ìŒ, VARëª¨í˜• ì±„íƒ**
# MAGIC - ì¶”ì„¸ ì—†ìŒ ì¼€ì´ìŠ¤ : p-valueê°’ì´ 0.13ë¡œ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•˜ì—¬ **ê³µì ë¶„ê´€ê³„ ì—†ìŒ, VARëª¨í˜• ì±„íƒ**
