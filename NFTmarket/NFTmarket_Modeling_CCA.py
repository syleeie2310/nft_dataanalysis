# Databricks notebook source
import numpy as np
import pandas as pd

# COMMAND ----------

# MAGIC %md
# MAGIC # ì •ì œ ë°ì´í„° ë¡œë“œ

# COMMAND ----------

data = pd.read_csv('/dbfs/FileStore/nft/nft_market_cleaned/total_220222_cleaned.csv', index_col = "Date", parse_dates=True, thousands=',')

# COMMAND ----------

data.info()

# COMMAND ----------

data.tail()

# COMMAND ----------

# MAGIC %md
# MAGIC # ì‹œê³„ì—´ íŠ¹ì„± ë¶„ì„

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. ì •ìƒì„± íŒë‹¨
# MAGIC ### ìê¸° ìƒê´€ í•¨ìˆ˜(ACF)
# MAGIC - ì”ì°¨ë“¤ì´ ì‹œê°„ì˜ íë¦„ì—ì„œ ë…ë¦½ì ì¸ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•¨(acfì— 0ì— ê°€ê¹Œìš°ë©´ ë…ë¦½ì )
# MAGIC - ì‹œì°¨ê°€ í´ìˆ˜ë¡ 0ì— ê°€ê¹Œì›Œì§€ë©°, ì •ìƒ ì‹œê³„ì—´ì€ ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¥´ê²Œ 0ì— ìˆ˜ë ´í•œë‹¤. 
# MAGIC - ACFëŠ” ë³´í†µ ì‹œê³„ì—´ì—ì„œ ê³¼ê±°ì˜ ì¢…ì†ë³€ìˆ˜(Y)ì™€ì˜ ë¹„êµë¥¼ í†µí•´ ê³„ì ˆì„± íŒë‹¨ì„ ì£¼ë¡œ í•œë‹¤.
# MAGIC - ë³´í†µ ì‹œê³„ì—´ ë¶„ì„ì—ì„œ ë§ì´ ì‚¬ìš©ì´ ë˜ë©°, í˜„ì¬ì˜ Yê°’ê³¼ ê³¼ê±°ì˜ Yê°’ì˜ ìƒê´€ì„±ì„ ë¹„êµí•œë‹¤. ì™œëƒí•˜ë©´, ê°ê°ì˜ Yê°’ì´ ë…ë¦½ì ì´ì–´ì•¼ ê²°ê³¼ ë¶„ì„ì´ ë” ì˜ë˜ê¸° ë•Œë¬¸ì´ë‹¤.(Yë¥¼ ì •ìƒí™”ì‹œí‚¤ë©´ ë¶„ì„ì´ ë” ì˜ëœë‹¤ëŠ” ê°œë…ê³¼ ê°™ë‹¤.) 
# MAGIC 
# MAGIC ### í¸ìê¸° ìƒê´€ í•¨ìˆ˜(PACF)
# MAGIC - ì‹œì°¨ì— ë”°ë¥¸ ì¼ë ¨ì˜ í¸ìê¸°ìƒê´€ì´ë©°, ì‹œì°¨ê°€ ë‹¤ë¥¸ ë‘ ì‹œê³„ì—´ ë°ì´í„°ê°„ì˜ ìˆœìˆ˜í•œ ìƒí˜¸ ì—°ê´€ì„±
# MAGIC 
# MAGIC ### ê·¸ë˜í”„ í•´ì„
# MAGIC - AR(p) íŠ¹ì„±: ACFëŠ” ì²œì²œíˆ ê°ì†Œí•˜ê³ , PACFëŠ” ì²˜ìŒ ì‹œì°¨ë¥¼ ì œì™¸í•˜ê³  ê¸‰ê²©íˆ ê°ì†Œ
# MAGIC - MA(q) íŠ¹ì„±: ACFê°€ ê¸‰ê²©íˆ ê°ì†Œí•˜ê³ , ACFëŠ” ì²œì²œíˆ ê°ì†Œ
# MAGIC - ê°ê° ê¸‰ê²©íˆ ê°ì†Œí•˜ëŠ” ì‹œì°¨ë¥¼ ëª¨ìˆ˜ë¡œ ì‚¬ìš©í•œë‹¤. AR -> PACF,    MA -> ACF
# MAGIC <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpcuWC%2Fbtq5CACTt5C%2FX3UFPPkwhZpjV59WygsV30%2Fimg.png">

# COMMAND ----------

from statsmodels.tsa.ar_model import AR
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, acf, pacf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from warnings import filterwarnings
filterwarnings("ignore")
plt.style.use("ggplot")

# COMMAND ----------

# MAGIC %md
# MAGIC ### [í•¨ìˆ˜] í”¼ì²˜ ì¹¼ëŸ¼ ë¶„ë¥˜ê¸°

# COMMAND ----------

# ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸°
def feature_classifier(data, feature):
    col_list = []
    for i in range(len(data.columns)):
        split_col = data.columns[i].split('_', maxsplit=1)[1]
        if split_col == feature:       
            col_list.append(data.columns[i])
        elif split_col == 'all_sales_usd' and feature == 'sales_usd' : #ì½œë ‰í„°ë¸”ë§Œ sales_usdì•ì— allì´ë¶™ì–´ì„œ ë”°ë¡œ ì²˜ë¦¬í•´ì¤Œ
            col_list.append('collectible_all_sales_usd')
        else :
            pass
    return col_list

# COMMAND ----------

# MAGIC %md
# MAGIC ### [í•¨ìˆ˜] ACF/PACF ì°¨íŠ¸ ìƒì„±

# COMMAND ----------

import plotly.express as px
import plotly.graph_objects as go

def autoCorrelation_stack(series):
    acf_array = acf(series.dropna(), alpha=0.05) 
    pacf_array = pacf(series.dropna(), alpha=0.05)
    
    array_list = [acf_array, pacf_array]
    for i in range(len(array_list)) :
        corr_array = array_list[i]
        lower_y = corr_array[1][:,0] - corr_array[0]
        upper_y = corr_array[1][:,1] - corr_array[0]

        fig = go.Figure()
        [fig.add_scatter(x=(x,x), y=(0,corr_array[0][x]), mode='lines',line_color='#3f3f3f') 
         for x in range(len(corr_array[0]))]
        fig.add_scatter(x=np.arange(len(corr_array[0])), y=corr_array[0], mode='markers', marker_color='#1f77b4',
                       marker_size=12)
        fig.add_scatter(x=np.arange(len(corr_array[0])), y=upper_y, mode='lines', line_color='rgba(255,255,255,0)')
        fig.add_scatter(x=np.arange(len(corr_array[0])), y=lower_y, mode='lines',fillcolor='rgba(32, 146, 230,0.3)',
                fill='tonexty', line_color='rgba(255,255,255,0)')
        fig.update_traces(showlegend=False)
        fig.update_xaxes(range=[-1,42])
        fig.update_yaxes(zerolinecolor='#000000')
        
        title= 'Autocorrelation (ACF)' if i == 0 else 'Partial Autocorrelation (PACF)' 
        fig.update_layout(title=title)
        fig.show()

# COMMAND ----------

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def autoCorrelationF(data, feature):
    
        # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    for col in col_list:
        series = data[col]

        acf_array = acf(series.dropna(), alpha=0.05) 
        pacf_array = pacf(series.dropna(), alpha=0.05)

        array_list = [acf_array, pacf_array]

        fig = make_subplots(rows=1, cols=2)

        for i in range(len(array_list)) :
            corr_array = array_list[i]
            lower_y = corr_array[1][:,0] - corr_array[0]
            upper_y = corr_array[1][:,1] - corr_array[0]

            [fig.add_scatter(x=(x,x), y=(0,corr_array[0][x]), mode='lines',line_color='#3f3f3f', row=1, col=i+1)
             for x in range(len(corr_array[0]))]


            fig.add_scatter(x=np.arange(len(corr_array[0])), y=corr_array[0], mode='markers', marker_color='#1f77b4', marker_size=12, row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=upper_y, mode='lines', line_color='rgba(255,255,255,0)', row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=lower_y, mode='lines',fillcolor='rgba(32, 146, 230,0.3)',
                fill='tonexty', line_color='rgba(255,255,255,0)', row=1, col=i+1)


            fig.update_traces(showlegend=False)
            fig.update_xaxes(range=[-1,42])
            fig.update_yaxes(zerolinecolor='#000000')

        fig.update_layout(title= f'<b>[{col}] Autocorrelation (ACF)                                 [{col}] Partial Autocorrelation (PACF)<b>', 
                         title_x=0.5)
        fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ### raw ë°ì´í„° ì‹œê°í™”
# MAGIC - í‰ê· ì´ ì¼ì •í•˜ì§€ ì•ŠìŒ, ëŒ€ì²´ë¡œ MAíŠ¹ì§•ì„ ê°€ì§ (PACF), ì°¨ë¶„ í•„ìš”
# MAGIC - 2ê°œì˜ ê²½í–¥ìœ¼ë¡œ ë‚˜ëˆ ì§
# MAGIC   - all, collectible, art, metaverse 
# MAGIC   - defi, game, utility

# COMMAND ----------

autoCorrelationF(data, 'average_usd') #raw df, feature

# COMMAND ----------

# MAGIC %md
# MAGIC ### logë³€í™˜ ë°ì´í„° ì‹œê°í™”
# MAGIC - rawë°ì´í„°ì™€ ìœ ì‚¬í•¨

# COMMAND ----------

autoCorrelationF(np.log1p(data), 'average_usd') #raw df, feature

# COMMAND ----------

# MAGIC %md
# MAGIC ### 2) ì°¨ë¶„
# MAGIC - ëŒ€ì²´ë¡œ ì •ìƒì„±ì„ ë³´ì—¬ 1ì°¨ë¡œ ì¶©ë¶„í•´ë³´ì„, ê·¸ëŸ¬ë‚˜ íŠ¹ì • ë³€ë™í­ì´ ë„ˆë¬´ ì»¤ì„œ ì „ì²´ì ì¸ íŒ¨í„´ì„ ì—¬ì „íˆ ë³´ê¸° ì–´ë ¤ì›€
# MAGIC - í° ë³€ë™í­ì´ ìˆìŒ ë¯¸ all, collectible, art, metaverse 
# MAGIC - allì€ 21.11.15 ì— í° ë³€ë™í­
# MAGIC - collectible, art, metaverse ê°€ 22.1.8ì— í° ë³€ë™ì´ ìˆìŒ
# MAGIC - defi, game, utilityëŠ” ëª¨ë‘ ë‹¤ë¦„

# COMMAND ----------

# MAGIC %md
# MAGIC #### rawë°ì´í„°+ì°¨ë¶„
# MAGIC - ì°¨ë¶„ì„ í†µí•´ ì •ìƒì„±ì„ ê°–ëŠ”ë‹¤.

# COMMAND ----------

import plotly.express as px
from plotly.subplots import make_subplots

def diff_plot(data, feature, plot):

    # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    diff_data = data[col_list].diff(periods=1).dropna() # dropna()ëŠ” diffë¥¼ í†µí•´ ìƒê¸´ ë°ì´í„° ê³µë°±ì œê±°
    
    if plot == 'line':
        # ë¼ì¸ ì°¨íŠ¸ ìƒì„± 
        for col in col_list:
#             series = data[col]
            # ë°ì´í„° ì°¨ë¶„
#             diff_series = series.diff(periods=1).dropna() 
            fig = px.line(diff_data[col], title= f'<b>[{col}] ì°¨ë¶„ ì‹œê°í™”<b>') 
            fig.update_layout(showlegend=False, title_x=0.5)
            fig.update_xaxes(None)
            fig.update_yaxes(None)
            fig.show()
    elif plot == 'acf':
        autoCorrelationF(diff_data, feature)

# COMMAND ----------

diff_plot(data, 'average_usd', 'line') #raw df, feature

# COMMAND ----------

diff_plot(data, 'average_usd', 'acf') #raw df, feature

# COMMAND ----------

# MAGIC %md
# MAGIC #### logë³€í™˜+ì°¨ë¶„
# MAGIC - ì—¬ì „íˆ ê°­ì´ ì»¤ì„œ ë³´ê¸° ì–´ë µë‹¤. ì ì ˆí•œì§€ ëª¨ë¥´ê² ë‹¤.

# COMMAND ----------

diff_plot(np.log1p(data), 'average_usd', 'line') #raw df, feature

# COMMAND ----------

# ì²«ë²ˆì§¸ëŠ” ìê¸°ìì‹ ê³¼ì˜ ìƒê´€ê´€ê³„ì´ë¯€ë¡œ 1ì´ ë‚˜ì˜¬ìˆ˜ë°–ì— ì—†ë‹¤.
diff_plot(np.log1p(data), 'average_usd', 'acf') #raw df, feature

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3) í†µê³„ì  ê°€ì„¤ ê²€ì •(Unit root test:ë‹¨ìœ„ê·¼ê²€ì •)
# MAGIC 
# MAGIC #### raw+ì°¨ë¶„ê³¼ log+ì°¨ë¶„ì„ ì •ìƒì„± í…ŒìŠ¤íŠ¸ í•´ë³´ì
# MAGIC - ê²€ì¦ ì¡°ê±´ ( p-value : 5%ì´ë‚´ë©´ rejectìœ¼ë¡œ ëŒ€ì²´ê°€ì„¤ ì„ íƒë¨ )
# MAGIC - ê·€ë¬´ê°€ì„¤(H0): non-stationary.
# MAGIC - ëŒ€ì²´ê°€ì„¤ (H1): stationary.
# MAGIC - ë‹¨ìœ„ê·¼ : ë‹¨ìœ„ê·¼ì´ë€ í™•ë¥ ë¡ ì˜ ë°ì´í„° ê²€ì •ì—ì„œ ì“°ì´ëŠ” ê°œë…ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì‹œê°„ì— ë”°ë¼ ì¼ì •í•œ ê·œì¹™ì„ ê°€ì§ì„ ê°€ì •í•œë‹¤
# MAGIC 
# MAGIC #### 1. Augmented Dickey-Fuller("ADF") Test
# MAGIC - ì‹œê³„ì—´ì— ë‹¨ìœ„ê·¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì •,ë‹¨ìœ„ê·¼ì´ ì¡´ì¬í•˜ë©´ ì •ìƒì„± ì‹œê³„ì—´ì´ ì•„ë‹˜.
# MAGIC - ê·€ë¬´ê°€ì„¤ì´ ë‹¨ìœ„ê·¼ì´ ì¡´ì¬í•œë‹¤.
# MAGIC - adf ì‘ì„ ìˆ˜ë¡ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°ì‹œí‚¬ í™•ë¥ ì´ ë†’ë‹¤
# MAGIC #### 2. Kwiatkowski-Phillips-Schmidt-Shin (â€œKPSSâ€) Test
# MAGIC - 1ì¢… ì˜¤ë¥˜ë¥¼ ë²”í•  ë¬¸ì œë¥¼ ì œê±°í•œ ì•ˆì •ì„± ê²€ì • ë°©ë²•
# MAGIC - ê·€ë¬´ê°€ì„¤ì´ ë‹¨ìœ„ê·¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.

# COMMAND ----------

# MAGIC %md
# MAGIC #### [í•¨ìˆ˜] ADF ê²€ì •

# COMMAND ----------

# adf ê²€ì •
from statsmodels.tsa.stattools import adfuller

def adf_test(data, feature):

    # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    for col in col_list:
        result = adfuller(data[col].values)
        print(f'[{col}] ADF Statistics: %f' % result[0])
        print('p-value: %f' % result[1])
        print('Critical values:')
        for key, value in result[4].items():
            print('\t%s: %.3f' % (key, value))
        print('='*50)

# COMMAND ----------

# adf ê²€ì •
from statsmodels.tsa.stattools import adfuller

def adf_test1(data):
#     print("Results of ADF Test")
    result = adfuller(data)
#     print('ADF Statistics: %f' % result[0])
#     print('p-value: %f' % result[1])
    return result
#     print('Critical values:')
#     for key, value in result[4].items():
#         print('\t%s: %.3f' % (key, value))

# COMMAND ----------

# MAGIC %md
# MAGIC #### [í•¨ìˆ˜] KPSS ê²€ì •

# COMMAND ----------

# KPSS ê²€ì •
from statsmodels.tsa.stattools import kpss

def kpss_test(data, feature):
    print("Results of KPSS Test:")
    
    # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    for col in col_list:
        result = kpss(data[col].values, regression="c", nlags="auto")
        print(f'<<{col}>>')
        kpss_output = pd.Series(
            result[0:3], index=["KPSS Statistic", "p-value", "Lags Used"] )
        for key, value in result[3].items():
            kpss_output["Critical Value (%s)" % key] = value
        print(kpss_output)
        print('='*50)

# COMMAND ----------

# KPSS ê²€ì •
from statsmodels.tsa.stattools import kpss

def kpss_test1(data):
#     print("Results of KPSS Test")
    result = kpss(data, regression="c", nlags="auto")
    kpss_output = pd.Series(
        result[0:3], index=["KPSS Statistic", "p-value", "Lags Used"] )
#     for key, value in result[3].items():
#         kpss_output["Critical Value (%s)" % key] = value
#     print(kpss_output[:1])   
    
#     print('KPSS Statistics: %f' % kpss_output[0])
#     print('p-value: %f' % kpss_output[1])
    return kpss_output


# COMMAND ----------

# MAGIC %md 
# MAGIC #### [í•¨ìˆ˜] ë‹¨ìœ„ê·¼ê²€ì • ì‹¤í–‰ê¸°

# COMMAND ----------

pd.options.display.float_format = '{: .4f}'.format

def URT(data, feature) :
    # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    adf_stats = []
    adf_Pval = []
    kpss_stats = []
    kpss_Pval = []
    total_list = []
    
    for col in col_list:
#         print(f'<<<<{col}>>>>')
        col_data = data[col]
        
        # ADFê²€ì •ê¸° í˜¸ì¶œ
        adf_result = adf_test1(col_data) 
        adf_stats.append(adf_result[0])
        adf_Pval.append(adf_result[1])
        
        # KPSSê²€ì •ê¸° í˜¸ì¶œ
        kpss_result = kpss_test1(col_data)
        kpss_stats.append(kpss_result[0])
        kpss_Pval.append(kpss_result[1])
        
        # ì¢…í•©
        if adf_result[1] <= 0.05 and kpss_result[1] >= 0.05:
            total_list.append('ALL Pass')
        elif adf_result[1] <= 0.05 or kpss_result[1] >= 0.05:
            total_list.append('One Pass')
        else :
            total_list.append('fail')
        
    # í…Œì´ë¸” ìƒì„±
#     col_list.append('total')
    result_df = pd.DataFrame(list(zip(adf_stats, adf_Pval, kpss_stats, kpss_Pval, total_list)), index = col_list, columns=['adf_stats', 'adf_Pval', 'KPSS_stats', 'KPSS_Pval', 'total'])
    
#     # adf statsê°€ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
#     result_df.sort_values(sort, inplace=True)
    
    return result_df             

# COMMAND ----------

# MAGIC %md
# MAGIC #### Raw+ì°¨ë¶„ ê²€ì •(ADF, KPSS)

# COMMAND ----------

# ì „ì²´ ê¸°ê°„ : artì œì™¸í•˜ê³  ëª¨ë‘ ì •ìƒì„±ì„ ê°€ì§
URT(data.diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# 2018ë…„ ì´í›„ :
URT(data['2018':].diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# 2018ë…„ ~ 2021ë…„ : all, defi, utilityë§Œ í†µê³¼
URT(data['2018':'2021'].diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# MAGIC %md
# MAGIC ####  Log+ì°¨ë¶„ ê²€ì •(ADF, KPSS)

# COMMAND ----------

# ì „ì²´ ê¸°ê°„ : utilityëŠ” ì¡°ê¸ˆ ì•½í•¨, 
URT(np.log1p(data).diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# ì „ì²´ê¸°ê°„ : artì™€ defië§Œ ëª¨ë‘ í†µê³¼
URT(np.log1p(data['2018':]).diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# 2018~2021 : artì™€ defië§Œ ëª¨ë‘ í†µê³¼
URT(np.log1p(data['2018':'2021']).diff(periods=1).dropna(), 'average_usd')

# COMMAND ----------

# MAGIC %md
# MAGIC ### 4) [ì¢…í•©ìš”ì•½] "average_usd"í”¼ì²˜ì˜ ì¹´í…Œê³ ë¦¬ë³„ ì •ìƒì„± ë¶„ì„
# MAGIC 
# MAGIC - ì°¨ë¶„ì€ 1íšŒë©´ ì¶©ë¶„í•˜ë‹¤. MAê°’ì€ rawëŠ” 1, logëŠ” 0ìœ¼ë¡œ í™•ì¸ë¨, (P=?, D=1, Q=1)
# MAGIC   - acf/pacf ê·¸ë˜í”„ì—ì„œ  pì™€ qê°’ì„ ì„ ì •í•˜ëŠ” ê²ƒì€ ê¶Œì¥í•˜ì§€ ì•ŠìŒ, ì •í™•í•˜ì§€ ì•Šê³  í•´ì„í•˜ê¸° ì–´ë ¤ì›€
# MAGIC   - ì „ì²´ í–‰ ê¸¸ì´ì˜ logë³€í™˜ ê°’ì„ ìµœëŒ€ì¹˜ë¡œ, arì„ ì‹¤í—˜í•˜ëŠ” ê°€ì´ë“œê°€ ìˆìœ¼ë‚˜ ì •í™•í•˜ì§€ ì•ŠìŒ, ê°’ì´ ë³€í•˜ì§€ ì•ŠëŠ”ì§€ ë” ì²´í¬í•´ë´ì•¼í•¨
# MAGIC - í†µê³„ì  ê°€ì„¤ ê²€ì •
# MAGIC   - ì¹´í…Œê³ ë¦¬ë³„, raw/logë³„, ê¸°ê°„ë³„ ê²°ê³¼ê°€ ëª¨ë‘ ë‹¬ë¼ì„œ í˜¼ë€ìŠ¤ëŸ½ë‹¤..
# MAGIC   - raw+ì°¨ë¶„ì™€ log+ì°¨ë¶„, ì¤‘ì— ë¬´ì—‡ì„ ê³¨ë¼ì•¼í•˜ë‚˜?
# MAGIC   - ì¹´í…Œê³ ë¦¬ëŠ” ì–´ë–»ê²Œ ê³¨ë¼ì•¼ í•˜ë‚˜?

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. ì‹œê³„ì—´ ë¶„í•´
# MAGIC - ì‹œê³„ì—´ ì„±ë¶„ : ì¶”ì„¸, ê³„ì ˆ/ìˆœí™˜, ë¶ˆê·œì¹™(ë‚˜ë¨¸ì§€)
# MAGIC - statsmodels.tsa.seasonal.STL : LOESSë¥¼ ì‚¬ìš©í•œ ê³„ì ˆ ì¶”ì„¸ ë¶„í•´
# MAGIC - statsmodels.tsa.seasonal.seasonal_decompose : ê°€ì‚° ë˜ëŠ” ê³±ì…ˆ ëª¨ë¸ê³¼ ê°™ì€ ì„ í˜• ëª¨ë¸
# MAGIC   - (1) ì‹œë„í‘œ (time series plot)ë¥¼ ë³´ê³  ì‹œê³„ì—´ì˜ ì£¼ê¸°ì  ë°˜ë³µ/ê³„ì ˆì„±ì´ ìˆëŠ”ì§€, ê°€ë²• ëª¨í˜•(additive model, y = t + s + r)ê³¼ ìŠ¹ë²• ëª¨í˜•(multiplicative model, y = t * s * r) ì¤‘ ë¬´ì—‡ì´ ë” ì í•©í• ì§€ íŒë‹¨ì„ í•©ë‹ˆë‹¤. 
# MAGIC 
# MAGIC  
# MAGIC 
# MAGIC <ê°€ë²• ëª¨í˜•ì„ ê°€ì • ì‹œ>
# MAGIC 
# MAGIC   - (2) ì‹œê³„ì—´ ìë£Œì—ì„œ ì¶”ì„¸(trend)ë¥¼ ë½‘ì•„ë‚´ê¸° ìœ„í•´ì„œ ì¤‘ì‹¬ ì´ë™ í‰ê· (centered moving average)ì„ ì´ìš©í•©ë‹ˆë‹¤. 
# MAGIC 
# MAGIC  
# MAGIC 
# MAGIC   - (3) ì› ìë£Œì—ì„œ ì¶”ì„¸ ë¶„í•´ê°’ì„ ë¹¼ì¤ë‹ˆë‹¤(detrend). ê·¸ëŸ¬ë©´ ê³„ì ˆ ìš”ì¸ê³¼ ë¶ˆê·œì¹™ ìš”ì¸ë§Œ ë‚¨ê²Œ ë©ë‹ˆë‹¤. 
# MAGIC 
# MAGIC  
# MAGIC 
# MAGIC   - (4) ë‹¤ìŒì— ê³„ì ˆ ì£¼ê¸° (seasonal period) ë¡œ detrend ì´í›„ ë‚¨ì€ ê°’ì˜ í•©ì„ ë‚˜ëˆ„ì–´ì£¼ë©´ ê³„ì ˆ í‰ê· (average seasonality)ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: 01ì›” ê³„ì ˆ í‰ê·  = (2020-01 + 2021-01 + 2022-01 + 2023-01)/4, 02ì›” ê³„ì ˆ í‰ê·  = (2020-02 + 2021-02 + 2022-02 + 2023-02)/4). 
# MAGIC 
# MAGIC  
# MAGIC 
# MAGIC   - (5) ì›ë˜ì˜ ê°’ì—ì„œ ì¶”ì„¸ì™€ ê³„ì ˆì„± ë¶„í•´ê°’ì„ ë¹¼ì£¼ë©´ ë¶ˆê·œì¹™ ìš”ì¸(random, irregular factor)ì´ ë‚¨ê²Œ ë©ë‹ˆë‹¤. 

# COMMAND ----------

# MAGIC %md
# MAGIC #### [í•¨ìˆ˜] ì‹œê°í™”

# COMMAND ----------

from plotly.subplots import make_subplots
from statsmodels.tsa.seasonal import DecomposeResult, seasonal_decompose

def plot_seasonal_decompose(result:DecomposeResult, dates:pd.Series=None, title:str="Seasonal Decomposition"):
    x_values = dates if dates is not None else np.arange(len(result.observed))
    return (
        make_subplots(
            rows=4,
            cols=1,
            subplot_titles=["Observed", "Trend", "Seasonal", "Residuals"],
        )
        .add_trace(
            go.Scatter(x=x_values, y=result.observed, mode="lines", name='Observed'),
            row=1,
            col=1,
        )
        .add_trace(
            go.Scatter(x=x_values, y=result.trend, mode="lines", name='Trend'),
            row=2,
            col=1,
        )
        .add_trace(
            go.Scatter(x=x_values, y=result.seasonal, mode="lines", name='Seasonal'),
            row=3,
            col=1,
        )
        .add_trace(
            go.Scatter(x=x_values, y=result.resid, mode="lines", name='Residual'),
            row=4,
            col=1,
        )
        .update_layout(
            height=900, title=f'<b>{title}</b>', margin={'t':100}, title_x=0.5, showlegend=False
        )
    )

# COMMAND ----------

# MAGIC %md
# MAGIC #### ì‹¤í—˜1 (ë¯¸ì°¨ë¶„)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### raw ë°ì´í„°

# COMMAND ----------

import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
df = data['collectible_average_usd']
decomposition = seasonal_decompose(df, model='additive', period=365) 
# ì¼ìë°ì´í„°... ê¸°ê°„ ì–´ì¼€í•¨ ã…œ, ìë™ ë‹¬ë ¥ë³€ë™ì´ ì•ˆë˜ê³  ë§ì…ˆë¶„í•´ë§Œ ê°€ëŠ¥
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
df = data['game_average_usd']
decomposition = seasonal_decompose(df, model='additive', period=365) 
# ì¼ìë°ì´í„°... ê¸°ê°„ ì–´ì¼€í•¨ ã…œ, ìë™ ë‹¬ë ¥ë³€ë™ì´ ì•ˆë˜ê³  ë§ì…ˆë¶„í•´ë§Œ ê°€ëŠ¥
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ##### logë³€í™˜ ë°ì´í„°

# COMMAND ----------

df = np.log1p(data['collectible_average_usd'])
decomposition = seasonal_decompose(df, model='additive', period=365) # ì¼ìë°ì´í„°...
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ##### ì§‘ê³„ ë°ì´í„°

# COMMAND ----------

from statsmodels.tsa.seasonal import seasonal_decompose
dataM_median = data.resample('M').median() # ì›” ì¤‘ì•™ê°’ ë°ì´í„° ìƒì„±
df = dataM_median['collectible_average_usd']

decomposition = seasonal_decompose(df, model='additive', period=12) # ì¼ìë°ì´í„°...
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC #### ì‹¤í—˜2 (1ì°¨ë¶„)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### raw+ì°¨ë¶„

# COMMAND ----------

import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
df = data['collectible_average_usd'].diff(periods=1).dropna()
decomposition = seasonal_decompose(df, model='additive', period=365) 
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ##### log+ì°¨ë¶„

# COMMAND ----------

# ì°¨ë¶„ë¨¼ì €í•˜ê³  ë¡œê·¸ë³€í™˜í•˜ë©´ ì˜¤ë¥˜ë‚¨..
df = np.log1p(data['collectible_average_usd']).diff(periods=1).dropna()
decomposition = seasonal_decompose(df, model='additive', period=365) 
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ##### ì§‘ê³„+ì°¨ë¶„

# COMMAND ----------

# ì°¨ë¶„-> ì§‘ê³„ ì™€, ì§‘ê³„->ì°¨ë¶„ì˜ ê·¸ë˜í”„ê°€ ë‹¤ë¦„, ë¬´ì—‡ì´ ì •í™•í• ê¹Œ?
from statsmodels.tsa.seasonal import seasonal_decompose
dataM_median = (data.resample('M').median()).diff(periods=1).dropna() 
# dataM_median = (data.diff(periods=1).dropna()).resample('M').median() 
df = dataM_median['collectible_average_usd']

decomposition = seasonal_decompose(df, model='additive', period=12) # ì¼ìë°ì´í„°...
fig = plot_seasonal_decompose(decomposition, dates=df.index)
fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC #### [ì¢…í•©ìš”ì•½] : raw, log, ì§‘ê³„, ì°¨ë¶„ê¹Œì§€ ëª¨ë‘ ê³„ì ˆì„±ì„ ë³´ì´ê³  ë¶ˆê·œì¹™ì—ì„œë„ íŒ¨í„´ì´ ìˆë‹¤. SARIMAë¥¼ ì¨ë³´ì.  ë‹¤ë§Œ 21ë…„ë„ ì´í›„ë¶€í„°ëŠ” ê³„ì ˆì„±ì´ ì—†ì–´ ì˜ˆì¸¡ ìš°ë ¤
# MAGIC - collectible_average_usdëŠ” ê³„ì ˆì„±ì´ ìˆë‹¤.  ë¶ˆê·œì¹™ì—ì„œë„ íŒ¨í„´ì„ ë³´ì¸ë‹¤. -> ì˜ˆì¸¡ì´ ê°€ëŠ¥í•  ê²ƒ ê°™ì§€ë§Œ
# MAGIC - [ì‹¤í—˜1] 20ë…„ê¹Œì§€ ê³„ì ˆì„±ì™€ ë¶ˆê·œì¹™(ë°˜ë³µ) íŠ¹ì§•ì´ ìˆìŒ. 21ë…„ë¶€í„° ì—…ì–´ ì˜ˆì¸¡ë ì§€ ì˜ë¬¸, -> ì§€ìˆ˜í‰í™œì„ í•´ì•¼í•  ê²ƒ ê°™ì€ë°.. 
# MAGIC   - rawì¶”ì„¸ : 18ë…„ í•˜ë½, 21ë…„ ê¸‰ìƒìŠ¹
# MAGIC   - rawê³„ì ˆì„± : 1ë…„ ì£¼ê¸°ë¡œ 7ì›”ì—ê¸‰ìƒìŠ¹í•˜ê³  ì´í›„ í•˜ë½ì„¸
# MAGIC   - rawë¶ˆê·œì¹™ : 20ë…„ ì¤‘ë°˜ê¹Œì§€ 1ë…„ê°„ ìƒìŠ¹í•˜ë‹¤ 8ì›” í•˜ë½ íŠ¹ì§•ì´ ìˆì—ˆìœ¼ë‚˜,  21ë…„ë¶€í„° í•˜ë½ ì§€ì†
# MAGIC   - logëŠ” ê³„ì ˆì„±ì´ 18ë…„ 1ì›”ë¶€í„° ëœ€, ë¡œê·¸ë³€í™˜ìœ¼ë¡œ ê´€ì¸¡ê°’ê³¼ ì™œê³¡ì´ ìƒê²¨ ë¶€ì í•©
# MAGIC - [ì‹¤í—˜2] í•´ì„ ì–´ë ¤ì›€, ìœ ì˜ë¯¸í•œì§€?
# MAGIC    -ì°¨ë¶„+ì§‘ê³„ëŠ” ì‹¤í—˜1ê³¼ ìœ ì‚¬í•¨ 

# COMMAND ----------

# MAGIC %md
# MAGIC ### Seasonal adjustment
# MAGIC - ê³„ì ˆì„±ì´ ìˆê¸´í•˜ì§€ë§Œ, ì¶”ì„¸ì— í¬ê²Œ ì˜í–¥ì„ ì£¼ì§„ ëª»í•¨, ì˜í–¥ë ¥ì´ ì‘ì€ ë“¯í•¨, íŠ¸ëœë“œ ì˜í–¥ì´ ë” í° ë°ì´í„°ì„. ìµœê·¼ íŠ¸ëœë“œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ê³ ë ¤ê°€ í•„ìš”í•¨(ex ì§€ìˆ˜í‰í™œë²•)
# MAGIC - ê³„ì ˆì„±ìœ¼ë¡œ ì¡°ì •ëœ ë°ì´í„°, (ì›ë°ì´í„°ì— ê³„ì ˆì„±ì„ ëºŒ)
# MAGIC - ê³„ì ˆì„±ìœ¼ë¡œ ì¡°ì •ëœ ì‹œê³„ì—´ì—ëŠ” ì¶”ì„¸-ì£¼ê¸° ì„±ë¶„ë„ ìˆê³  ë‚˜ë¨¸ì§€ ì„±ë¶„ë„ ìˆìŠµë‹ˆë‹¤.
# MAGIC - ê·¸ë˜ì„œ, ì‹œê³„ì—´ì´ â€œë§¤ë„ëŸ½ì§€â€ ì•Šê³ , â€œí•˜ë½ì„¸â€ë‚˜ â€œìƒìŠ¹ì„¸â€ë¼ëŠ” í‘œí˜„ì´ ì˜¤í•´ë¥¼ ë¶ˆëŸ¬ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# MAGIC - ì‹œê³„ì—´ì—ì„œ ì „í™˜ì ì„ ì‚´í´ë³´ëŠ” ê²ƒê³¼ ì–´ë–¤ ë°©í–¥ìœ¼ë¡œì˜ ë³€í™”ë¥¼ í•´ì„í•˜ë ¤ëŠ” ê²ƒì´ ëª©ì ì´ë¼ë©´, ê³„ì ˆì„±ìœ¼ë¡œ ì¡°ì •ëœ ë°ì´í„°ë³´ë‹¤ëŠ” ì¶”ì„¸-ì£¼ê¸° ì„±ë¶„ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ë‚«ìŠµë‹ˆë‹¤.

# COMMAND ----------

# ë¯¸ì°¨ë¶„ raw ë°ì´í„° ê³„ì ˆì„± ì¡°ì •
df = data['collectible_average_usd']
decomposition = seasonal_decompose(df, model='additive', period=365) 
# decomposition_trend = decomposition.trend
decomposition_seasonal = decomposition.seasonal
df_adjusted = (df - decomposition_seasonal).rename('seasonal adjusted')
df_adjusted

# COMMAND ----------

# ìŒìˆ˜ê°€ ìˆë„¤..;
df_adjusted.describe()

# COMMAND ----------

from plotly.subplots import make_subplots
import plotly.graph_objects as go

fig = go.Figure([
    # ì› ë°ì´í„°-------------------------------------------------------
    go.Scatter(x = df.index, y = df, name = "raw", mode = 'lines')
    # ê³„ì ˆì„± ì¡°ì • ë°ì´í„°------------------------------------------------------
    , go.Scatter(x = df_adjusted.index, y = df_adjusted, name = "adjusted", mode = 'lines')
])
fig.update_layout(title = '<b>[collectible_average_usd] ê³„ì ˆì„± ì¡°ì • ë¹„êµ<b>', title_x=0.5, legend=dict(orientation="h", xanchor="right", x=1, y=1.1))
fig.update_yaxes(ticklabelposition="inside top", title=None)
fig.show()

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %md
# MAGIC # êµì°¨ ë° ì‹œì°¨ ìƒê´€ê³„ìˆ˜(Cross Correlation)
# MAGIC - ìœ„í‚¤í”¼ë””ì•„: https://en.wikipedia.org/wiki/Cross-correlation
# MAGIC - 1d ë°°ì—´ : statsmodelCCF, numpy.correlate, matplotlib.pyplot.xcorr(numpy.correlate ê¸°ë°˜)
# MAGIC   - https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.ccf.html
# MAGIC   - https://numpy.org/doc/stable/reference/generated/numpy.correlate.html#numpy.correlate
# MAGIC   - numpy.correlateFFTë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨ë³¼ë£¨ì…˜ì„ ê³„ì‚°í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í° ë°°ì—´(ì¦‰, n = 1e5)ì—ì„œ ëŠë¦¬ê²Œ ìˆ˜í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° scipy.signal.correlateë°”ëŒì§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# MAGIC - 2d ë°°ì—´ : scipy.signal.correlate2d , scipy.stsci.convolve.correlate2d 
# MAGIC - êµì°¨ ë° ì‹œì°¨ìƒê´€ê³„ìˆ˜ëŠ” tê¸°ì˜ íŠ¹ì •(ê¸°ì¤€)ë³€ìˆ˜ xì˜ ê°’(ğ’™ğ’•)ê³¼ t+kê¸°ì— ê´€ì°°ëœ yê°’(ğ’šğ’•+ğ’Œ) ê°„ì˜ ìƒê´€ê´€ê³„ì˜ ì •ë„ë¥¼ ë‚˜íƒ€ëƒ„
# MAGIC - k=0ì¸ ê²½ìš° ì¦‰, ğœ¸ğŸì¸ ê²½ìš°ë¥¼ êµì°¨ìƒê´€ê³„ìˆ˜(cross correlation coefficient)ë¼ê³  í•˜ê³ , kâ‰ 0ì¸ ê²½ìš° ë¥¼ ì‹œì°¨ìƒê´€ê³„ìˆ˜(leads and lags correlationë¼ê³ ë„ í•¨
# MAGIC - êµì°¨ìƒê´€ê³„ìˆ˜ í•´ì„
# MAGIC   - ğœ¸ğŸ> 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(pro-cyclical:ê²½ê¸°ìˆœì‘)
# MAGIC   - ğœ¸ğŸ< 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(counter-cyclical:ê²½ê¸°ì—­í–‰)
# MAGIC   - ğœ¸ğŸ = 0 : ë‘ ë³€ìˆ˜ë“¤ì´ ì„œë¡œ ê²½ê¸°ì¤‘ë¦½ì 
# MAGIC - ì‹œì°¨ìƒê´€ê³„ìˆ˜ í•´ì„
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ ì–‘(+)ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì˜ í›„í–‰ì§€í‘œ
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ ìŒ(-)ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì˜ ì„ í–‰ì§€í‘œ
# MAGIC   - ğœ¸ğ’Œì˜ ê°’ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì‹œì°¨ kê°€ 0ì´ë©´ í•´ë‹¹ë³€ìˆ˜ ğ’šğ’•ëŠ” ğ’™ğ’•ì™€ ë™í–‰ì§€í‘œ

# COMMAND ----------

pd.options.display.float_format = '{: .4f}'.format

# COMMAND ----------

# MAGIC %md
# MAGIC ## ì˜ˆì œ1 : statsmodel CCF
# MAGIC - adjusted (=unbiased): ì°¸ì´ë©´ êµì°¨ ìƒê´€ì˜ ë¶„ëª¨ëŠ” nkì´ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ nì…ë‹ˆë‹¤.
# MAGIC   - í¸í–¥ë˜ì§€ ì•Šì€ ê²ƒì´ ì°¸ì´ë©´ ìê¸°ê³µë¶„ì‚°ì˜ ë¶„ëª¨ê°€ ì¡°ì •ë˜ì§€ë§Œ ìê¸°ìƒê´€ì€ í¸í–¥ë˜ì§€ ì•Šì€ ì¶”ì •ëŸ‰ì´ ì•„ë‹™ë‹ˆë‹¤.
# MAGIC - fft : Trueì´ë©´ FFT ì»¨ë³¼ë£¨ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ê¸´ ì‹œê³„ì—´ì— ëŒ€í•´ ì„ í˜¸ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

# COMMAND ----------

#define data 
marketing = np.array([3, 4, 5, 5, 7, 9, 13, 15, 12, 10, 8, 8])
revenue = np.array([21, 19, 22, 24, 25, 29, 30, 34, 37, 40, 35, 30]) 

# COMMAND ----------

import statsmodels.api as sm

#calculate cross correlation
sm.tsa.stattools.ccf(marketing, revenue, adjusted=False)

# COMMAND ----------

#  ì‹œì°¨0ì—ì„œ êµì°¨ìƒê´€ì€ 0.771, ì‹œì°¨1ì—ì„œ êµì°¨ìƒê´€ì€ 0.462, ì‹œì°¨2ì—ì„œ êµì°¨ìƒê´€ì€ 0.194, ì‹œì°¨3ì—ì„œ êµì°¨ìƒê´€ì€ -0.061
#  íŠ¹ì • ì›”ì—ì„œ ë§ˆì¼€íŒ…ë¹„ìš©ì„ ì§€ì¶œí•˜ë©´ ë‹¤ìŒ 2ê°œì›”ë™ì•ˆì˜ ìˆ˜ìµì¦ê°€ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.

# COMMAND ----------

# MAGIC %md
# MAGIC ## ì˜ˆì œ2 : numpy.correlate

# COMMAND ----------

import numpy

myArray = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
myArray = numpy.array(myArray)
result = numpy.correlate(myArray, myArray, mode = 'full')
print(result)
print(result.size)
result = result[result.size // 2 :] # ì™„ì „íˆ ê²¹ì¹˜ëŠ” ì§€ì ì¸ ì¤‘ê°„ ì´í›„ë¶€í„° ë´ì•¼í•¨
print(result)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ccfì™€ correlate ì™€ì˜ ì°¨ì´
# MAGIC - https://stackoverflow.com/questions/24616671/numpy-and-statsmodels-give-different-values-when-calculating-correlations-how-t
# MAGIC - ccfëŠ” np.correlate ë² ì´ìŠ¤ì´ì§€ë§Œ, í†µê³„ì ì˜ë¯¸ì—ì„œ ìƒê´€ê´€ê³„ë¥¼ ìœ„í•œ ì¶”ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•¨
# MAGIC - numpyê°€ í‘œì¤€í¸ì°¨ì˜ ê³±ìœ¼ë¡œ ê³µë¶„ì‚°ì„ ì •ê·œí™” í•˜ì§€ ì•ŠìŒ, ê°’ì´ ë„ˆë¬´ í¼
# MAGIC - ccfëŠ” í•©ì„±ê³±ì „ì— ì‹ í˜¸ì˜ í‰ê· ì„ ë¹¼ê³  ê²°ê³¼ë¥¼ ì²«ë²ˆì§¸ ì‹ í˜¸ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆ„ì–´ í†µê³„ì—ì„œì™€ ê°™ì€ ìƒê´€ê´€ê³„ ì •ì˜ì— ë„ë‹¬í•¨
# MAGIC - í†µê³„ ë° ì‹œê³„ì—´ ë¶„ì„ì—ì„œëŠ” êµì°¨ìƒê´€í•¨ìˆ˜ë¥¼ ì •ê·œí™”í•˜ì—¬ ì‹œê°„ì¢…ì† ìƒê´€ê³„ìˆ˜ë¥¼ ì–»ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤.
# MAGIC - ìê¸° ìƒê´€ì„ ìƒê´€ ê´€ê³„ë¡œ í•´ì„í•˜ë©´ í†µê³„ì  ì˜ì¡´ë„ ì˜ ì²™ë„ê°€ ì—†ëŠ” ì¸¡ì •ê°’ì´ ì œê³µ ë˜ê³  ì •ê·œí™”ëŠ” ì¶”ì •ëœ ìê¸° ìƒê´€ì˜ í†µê³„ì  ì†ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ë•Œë¬¸ì— ì •ê·œí™”ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
# MAGIC - <ì•„ë˜ ì†ŒìŠ¤ì½”ë“œ ì°¸ê³ >
# MAGIC 
# MAGIC ```
# MAGIC def ccovf(x, y, unbiased=True, demean=True):
# MAGIC     n = len(x)
# MAGIC     if demean:
# MAGIC         xo = x - x.mean()
# MAGIC         yo = y - y.mean()
# MAGIC     else:
# MAGIC         xo = x
# MAGIC         yo = y
# MAGIC     if unbiased:
# MAGIC         xi = np.ones(n)
# MAGIC         d = np.correlate(xi, xi, 'full')
# MAGIC     else:
# MAGIC         d = n
# MAGIC     return (np.correlate(xo, yo, 'full') / d)[n - 1:]
# MAGIC 
# MAGIC def ccf(x, y, unbiased=True):
# MAGIC     cvf = ccovf(x, y, unbiased=unbiased, demean=True)
# MAGIC     return cvf / (np.std(x) * np.std(y))
# MAGIC ```

# COMMAND ----------

col_list = feature_classifier(data, 'average_usd')

# COMMAND ----------

avgusd = data[col_list]
avgusd.head()

# COMMAND ----------

avgusd_game = avgusd['game_average_usd']
avgusd_game.head()

# COMMAND ----------

# raw
plt.plot(avgusd_game)

# COMMAND ----------

result = np.correlate(avgusd_game, avgusd_game, 'full')
print(result[result.size // 2 :])

# COMMAND ----------

# numpy.correlate
import numpy as np
from matplotlib import pyplot as plt
from statsmodels.tsa.stattools import ccf

#Calculate correlation using numpy.correlate
def corr(x,y):
    result = numpy.correlate(x, y, mode='full')
    return result[result.size//2:]

#Using numpy i get this
plt.plot(corr(avgusd_game,avgusd_game))

# COMMAND ----------

# statsmodel.ccf
plt.plot(ccf(avgusd_game, avgusd_game, adjusted=False))

# COMMAND ----------

# MAGIC %md
# MAGIC ### (êµì°¨)ìƒê´€ê³„ìˆ˜ ì‹œê°í™”
# MAGIC - https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xcorr.html
# MAGIC   - ì´ê±´ ì–´ë–»ê²Œ ì»¤ìŠ¤í…€ì„ ëª»í•˜ê² ë‹¤..

# COMMAND ----------

import matplotlib.pyplot as plt
from warnings import filterwarnings
filterwarnings("ignore")
plt.style.use("ggplot")

# COMMAND ----------

# numply.correlate
result = numpy.correlate(avgusd_game, avgusd_game, mode='full')
npcorr = result[result.size//2:]

nlags = len(npcorr)
leng = len(avgusd_game)

# /* Compute the Significance level */
conf_level = 2 / np.sqrt(nlags)
print('conf_level= ', conf_level)

# /* Draw Plot */
plt.figure(figsize=(30,10), dpi=80)
plt.hlines(0, xmin=0, xmax=leng, color='gray')  # 0 axis
plt.hlines(conf_level, xmin=0, xmax=leng, color='gray')
plt.hlines(-conf_level, xmin=0, xmax=leng, color='gray')

plt.bar(x=np.arange(len(npcorr)), height=npcorr, width=.3)
# plt.bar(x=avgusd_game.index, height=ccs, width=.3) # x ê¸¸ì´ëŠ” ê°™ì€ë°..  ì•ˆë¨..ccsê°’ê³¼ ì¸ë±ìŠ¤ì™€ ë§¤í•‘ì´ ì•ˆë˜ëŠ” ë“¯

# /* Decoration */
plt.title('Cross Correlation Plot <numpy.correlate>', fontsize=22)
plt.xlim(0,len(npcorr))
plt.show()

# COMMAND ----------

# ccf
ccs = ccf(avgusd_game, avgusd_game, adjusted=False)
nlags = len(ccs)
leng = len(avgusd_game)

# /* Compute the Significance level */
conf_level = 2 / np.sqrt(nlags)
print('conf_level= ', conf_level)

# /* Draw Plot */
plt.figure(figsize=(30,10), dpi=80)

plt.hlines(0, xmin=0, xmax=leng, color='gray')  # 0 axis
plt.hlines(conf_level, xmin=0, xmax=leng, color='gray')
plt.hlines(-conf_level, xmin=0, xmax=leng, color='gray')

plt.bar(x=np.arange(len(ccs)), height=ccs, width=.3)
# plt.bar(x=avgusd_game.index, height=ccs, width=.3) # ì•ˆë˜ë„¤..

# /* Decoration */
plt.title('Cross Correlation Plot <statsmodels.CCF>', fontsize=22)
plt.xlim(0,len(ccs))
plt.show()

# COMMAND ----------

# ì•½ 250ì¼ê¹Œì§€ ë‘ë³€ìˆ˜ ë“¤ì´ ì„œë¡œ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ë³€í™”(pro-cyclical:ê²½ê¸°ìˆœì‘)

# COMMAND ----------

# MAGIC %md
# MAGIC ## í•¨ìˆ˜ ìƒì„±

# COMMAND ----------

# ì¹´í…Œê³ ë¦¬ë³„ í”¼ì²˜ ë¶„ë¥˜ê¸°
def feature_classifier(data, feature):
    col_list = []
    for i in range(len(data.columns)):
        split_col = data.columns[i].split('_', maxsplit=1)[1]
        if split_col == feature:       
            col_list.append(data.columns[i])
        elif split_col == 'all_sales_usd' and feature == 'sales_usd' : #ì½œë ‰í„°ë¸”ë§Œ sales_usdì•ì— allì´ë¶™ì–´ì„œ ë”°ë¡œ ì²˜ë¦¬í•´ì¤Œ
            col_list.append('collectible_all_sales_usd')
        else :
            pass
    return col_list

# COMMAND ----------

# ccf ê³„ìˆ˜ ìƒì„±ê¸°
def ccf_data(data):
    ccfdata = ccf(data, data, adjusted=False)
    return ccfdata

# COMMAND ----------

## ccf ì°¨íŠ¸ ìƒì„±ê¸°
def ccfcc_plot(data, feature):
    # ì¹¼ëŸ¼ ë¦¬ìŠ¤íŠ¸í•¨ìˆ˜ í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    # ccf ê³„ìˆ˜ í•¨ìˆ˜ í˜¸ì¶œ
    for col in col_list:
        ccfdata = ccf_data(data[col])
    
        # /* Compute the Significance level */
        nlags = len(ccfdata)
        conf_level = 2 / np.sqrt(nlags)
#         print('conf_level= ', conf_level)
        print('êµì°¨ìƒê´€ê³„ìˆ˜ê°€ 0ì— ê°€ê¹Œìš´ ì§€ì  = ', min(np.where(ccfdata < 0)[0])-1)
        
        # /* Draw Plot */
        plt.figure(figsize=(30,10), dpi=80)

        plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis
        plt.hlines(conf_level, xmin=0, xmax=nlags, color='gray')
        plt.hlines(-conf_level, xmin=0, xmax=nlags, color='gray')

        plt.bar(x=np.arange(nlags), height=ccfdata, width=.3)
        # plt.bar(x=avgusd_game.index, height=ccs, width=.3) # ì•ˆë˜ë„¤..

        # /* Decoration */
        plt.title(f'Cross Correlation Plot <{col}>', fontsize=22)
        plt.xlim(0,nlags)
        plt.show()

# COMMAND ----------

# MAGIC %md
# MAGIC ## CCF-CC êµì°¨ ìƒê´€ê³„ìˆ˜(Cross Correlation)
# MAGIC - avgusd ì¹´í…Œê³ ë¦¬ë³„ ë¹„êµ, ì‹œê°€ì´ì•¡ê³¼ ë¹„êµ
# MAGIC - ë³€ìˆ˜ê°„ ë™í–‰ì„±(comovement) ì¸¡ì •
# MAGIC - ê²½ê¸°ìˆœì‘ì (pro-cyclical) / ê²½ê¸°ì¤‘ë¦½ì (a-cyclical) / ê²½ê¸°ì—­í–‰ì (counter-cyclical)

# COMMAND ----------

# MAGIC %md
# MAGIC #### ìê¸°êµì°¨ìƒê´€
# MAGIC - ì „ì²´ì¹´í…Œê³ ë¦¬ë³„ ì¸ë±ìŠ¤204~366 (ì•½6ê°œì›”ì—ì„œ 1ë…„ì£¼ê¸°)ê¹Œì§€ ë™í–‰ì„±ì´ ìˆìŒ

# COMMAND ----------

 # ì „ì²´ ì¹´í…Œê³ ë¦¬- ìê¸°êµì°¨ìƒê´€ ì‹œê°í™”
ccfcc_plot(data, 'average_usd')

# COMMAND ----------

# acfì™€ ë™ì¼í•œë“¯, ë¹„êµí•´ë³´ì. pacfëŠ” 50%ì´í•˜ ê¸¸ì´ë¡œë§Œ ê°€ëŠ¥
# ì ˆë°˜ë§Œ ë´ë„ acfëŠ” ë¹„ìŠ·í•˜ë„¤.

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def autoCorrelationF1(data, feature):
    
        # í”¼ì²˜ ë¶„ë¥˜ê¸° í˜¸ì¶œ
    col_list = feature_classifier(data, feature)
    
    for col in col_list:
        series = data[col]

        acf_array = acf(series.dropna(), alpha=0.05, nlags=850) 
        pacf_array = pacf(series.dropna(), alpha=0.05, nlags=850) # 50% ì´í•˜ ê¸¸ì´ê¹Œì§€ë§Œ ê°€ëŠ¥
        array_list = [acf_array, pacf_array]

        fig = make_subplots(rows=1, cols=2)

        for i in range(len(array_list)) :
            corr_array = array_list[i]
            lower_y = corr_array[1][:,0] - corr_array[0]
            upper_y = corr_array[1][:,1] - corr_array[0]
        
            [fig.add_scatter(x=(x,x), y=(0,corr_array[0][x]), mode='lines',line_color='#3f3f3f', row=1, col=i+1)
             for x in range(len(corr_array[0]))]

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=corr_array[0], mode='markers', marker_color='#1f77b4', marker_size=12, row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=upper_y, mode='lines', line_color='rgba(255,255,255,0)', row=1, col=i+1)

            fig.add_scatter(x=np.arange(len(corr_array[0])), y=lower_y, mode='lines',fillcolor='rgba(32, 146, 230,0.3)',
                fill='tonexty', line_color='rgba(255,255,255,0)', row=1, col=i+1)

# 
            fig.update_traces(showlegend=False)
#             fig.update_xaxes(range=[-1,42])
            fig.update_yaxes(zerolinecolor='#000000')

        fig.update_layout(title= f'<b>[{col}] Autocorrelation (ACF)                                 [{col}] Partial Autocorrelation (PACF)<b>', 
                         title_x=0.5)
        fig.show()

# COMMAND ----------

# MAGIC %md
# MAGIC #### ìƒí˜¸êµì°¨ìƒê´€
# MAGIC - ì¹´í…Œê³ ë¦¬ê°€ ë„ˆë¬´ ë§ë‹¤. 4ê°œë§Œ êµì°¨í•´ì„œ ë³´ì collectible_avgusd, game_avgusd, all_avgusd, all_sales_usd
# MAGIC - ì¸ë±ìŠ¤265~315 (ì•½9ê°œì›”ì—ì„œ 10ê°œì›”ì£¼ê¸°)ê¹Œì§€ ë™í–‰ì„±ì´ ìˆìŒ

# COMMAND ----------

## ccf ì°¨íŠ¸ ìƒì„±ê¸°
def ccfcc_plot1(data):

    col_list = ['collectible_average_usd', 'game_average_usd','all_average_usd', 'all_sales_usd']
    xcol_list = []
    ycol_list = []
    ccfdata_list = []
    
    for i in range(len(col_list)-1):
        for j in range(1, len(col_list)):
            xcol_list.append(col_list[i])
            ycol_list.append(col_list[j])
            ccfdata_list.append(ccf(data[col_list[i]], data[col_list[j]], adjusted=False))
            
    plt.figure(figsize=(30,30), dpi=80)
    plt.suptitle("Cross Correlation Plot", fontsize=40)

    for i in range(len(ccfdata_list)):   
        ccfdata = ccfdata_list[i]
        # /* Compute the Significance level */
        nlags = len(ccfdata)
        conf_level = 2 / np.sqrt(nlags)

        # /* Draw Plot */
        plt.subplot(3, 3, i+1)   
        plt.title(f'<{xcol_list[i]} X {ycol_list[i]}, {min(np.where(ccfdata < 0)[0])-1} >', fontsize=22)
        plt.bar(x=np.arange(nlags), height=ccfdata, width=.3)
        plt.xlim(0,nlags)        

        plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis
        plt.hlines(conf_level, xmin=0, xmax=nlags, color='gray')
        plt.hlines(-conf_level, xmin=0, xmax=nlags, color='gray')
      
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

# COMMAND ----------

# 1ì—´ì€ ìê¸°êµì°¨ìƒê´€, 2~3ì—´ì´ ìƒí˜¸êµì°¨ìƒê´€ ê·¸ë˜í”„
ccfcc_plot1(data)

# COMMAND ----------

# MAGIC %md
# MAGIC ## CCF-LC ì‹œì°¨ ìƒê´€ê³„ìˆ˜(leads and lags correlation)
# MAGIC - ì‹œì°¨ ìƒí˜¸ ìƒê´€(TLCC) https://dive-into-ds.tistory.com/96
# MAGIC - ì„ í–‰ì (leading) / ë™í–‰ì (coincident) / í›„í–‰ì (lagging)

# COMMAND ----------

# # lag ë°ì´í„°í”„ë ˆì„ ìƒì„±ê¸°
# def lag_df(data, num):
#     col = data.columns
#     for i in range(1,num+1):
#         data[i] = data[col].shift(i)
#     return data

# COMMAND ----------

pd.options.display.float_format = '{:.2f}'.format

# COMMAND ----------

#  ì‹œì°¨ìƒê´€ê³„ìˆ˜ ê³„ì‚°í•¨ìˆ˜
def TLCC(X, Y, lag):
    result=[]
    for i in range(lag):
        result.append(X.corr(Y.shift(i)))
    return result
#         print(i, np.round(result[i], 4))
#     print(f'ì‹œì°¨ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ì€ lag = <{np.argmax(result)}>')

# COMMAND ----------

TLCC(data['game_average_usd'], data['collectible_average_usd'], 14)

# COMMAND ----------

TLCC(data['all_average_usd'], data['all_sales_usd'], 14)

# COMMAND ----------

TLCC(data['all_average_usd'], data['all_number_of_sales'], 100)

# COMMAND ----------

# defiëŠ” 21-01-16ì— ë“¤ì–´ì˜´, ì´ 1704ì¤‘ã…‡ì— 400ê°œ, 1/6ë„ ì•ˆë˜ë¯€ë¡œ ì œì™¸í•œë‹¤
# data[['defi_average_usd']]['2021-01-15':]
avgusd_col_list = feature_classifier(data, 'average_usd')
avgusd_col_list.remove('defi_average_usd')
print(avgusd_col_list )

all_col_list = ['all_active_market_wallets','all_number_of_sales','all_average_usd','all_primary_sales','all_primary_sales_usd','all_sales_usd','all_secondary_sales','all_secondary_sales_usd','all_unique_buyers']
print(all_col_list)

# COMMAND ----------

## TLCC ì°¨íŠ¸ ìƒì„±ê¸°
def TLCC_plot(data, col_list, nlag):

    xcol_list = []
    ycol_list = []
    TLCC_list = []

    for i in range(len(col_list)):
        for j in range(1, len(col_list)):
            if col_list[i] == col_list[j]:
                pass
            else:
                xcol_list.append(col_list[i])
                ycol_list.append(col_list[j])
                tlccdata =TLCC(data[col_list[i]], data[col_list[j]], nlag)
                TLCC_list.append(tlccdata)

    plt.figure(figsize=(30,40))
    plt.suptitle("TLCC Plot", fontsize=40)
    
    ncols = 3
    nrows = len(xcol_list)//3+1
    
    for i in range(len(TLCC_list)): 
        tlccdata = TLCC_list[i]
        plt.subplot(nrows, ncols, i+1)   
        plt.title(f'<{xcol_list[i]} X {ycol_list[i]}, {np.argmax(tlccdata)} >', fontsize=22)
        plt.plot(np.arange(len(tlccdata)), tlccdata)
        plt.xlim(-1,len(tlccdata)+1)        
        plt.vlines(np.argmax(tlccdata), ymin=min(tlccdata), ymax=max(tlccdata) , color='blue',linestyle='--',label='Peak synchrony')
#         plt.hlines(0, xmin=0, xmax=nlags, color='gray')  # 0 axis

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()

# COMMAND ----------

 TLCC_plot(data, avgusd_col_list[1:], 14)

# COMMAND ----------

## TLCC table ìƒì„±ê¸°
def TLCC_table(data, col_list, nlag):

    xcol_list = []
    ycol_list = []
    TLCC_list = []
    havetomoreX = []
    havetomoreY = []

    for i in range(len(col_list)):
        for j in range(1, len(col_list)):
            if col_list[i] == col_list[j]:
                pass
            else:
                xcol_list.append(col_list[i])
                ycol_list.append(col_list[j])
                tlccdata = TLCC(data[col_list[i]], data[col_list[j]], nlag)
                TLCC_list.append(tlccdata)
#                 print(col_list[i], col_list[j])
#                 print(tlccdata)
#                 print(np.argmax(tlccdata))
#                 print(np.argmax(TLCC_list[i]))
                max_TLCC_idx = np.argmax(tlccdata)
                max_TLCC = np.round(max(tlccdata),4)
                if max_TLCC >= 0.7:
                    result = 'ë†’ìŒ'
                elif max_TLCC > 0.3 and max_TLCC < 0.7:
                    result = 'ë³´í†µ'
                else :
                    result = 'ë‚®ìŒ'
                print(col_list[i], '|', col_list[j], '|', max_TLCC_idx, '|', max_TLCC, '|', result)
            
                
                if max_TLCC_idx == nlag-1:
                    havetomoreX.append(col_list[i])
                    havetomoreY.append(col_list[j])

    return havetomoreX, havetomoreY

# COMMAND ----------

# gameì´ í›„í–‰ì¸ ê²½ìš°ëŠ” ëª¨ë‘ ê°€ì¥ ë†’ì€ lagê°€ ê°’ì´ ë†’ë‹¤. ë” ì˜¬ë ¤ë³´ì
# utilityëŠ” ë‹¤ë¥¸ì¹´í…Œê³ ë¦¬ì™€ ê±°ì˜ ì‹œì°¨ìƒê´€ì„±ì´ ì—†ë‹¤.
havetomoreX, havetomoreY = TLCC_table(data, avgusd_col_list[1:], 14)

# COMMAND ----------

print(havetomoreX)
print(havetomoreY)

# COMMAND ----------

for i in range(len(havetomoreX)):
    tlccdata = TLCC(data[havetomoreX[i]], data[havetomoreY[i]], 150)
    print(havetomoreX[i], havetomoreY[i], np.argmax(tlccdata), np.round(max(tlccdata),4))

# COMMAND ----------

# ì¹´í…Œê³ ë¦¬ë³„ í‰ê· ê°€ ì‹œì°¨ìƒê´€ë¶„ì„ ì‹¤í—˜ ê²°ê³¼
- ëŒ€ë¶€ë¶„ ì¹´í…Œê³ ë¦¬ì˜ ì‹œì°¨ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ì„ ë–„ëŠ” lag=0 ì¦‰, ë™í–‰ì„±ì„ ë³´ì¸ë‹¤.
- ì‹œì°¨ì§€ì—°ë˜ëŠ” ê²½ìš°ëŠ”,"game"ì´ í›„í–‰ì¼ë•Œ 34~143ì˜ ì§€ì—°ì„ ë³´ì¸ë‹¤.
- ì‹œì°¨ìƒê´€ì„±ì´ ë‚®ì€ ê²½ìš°ëŠ”, utility ì´ë‹¤. ì„ í–‰/í›„í–‰ ëª¨ë‘ ë‚®ìŒ
- ëŒ€í‘œë¡œ collectible-game 59ë¡œ ê³µì ë¶„ ê²€ì¦í•´ë³´ì

# COMMAND ----------

 TLCC_plot(data, all_col_list, 14)

# COMMAND ----------

# avgusdê°€ í›„í–‰ì¸ê²½ìš° lagê°’ì´ ê°€ì¥ ë†’ë‹¤. ë” ì˜¬ë ¤ë³´ì

havetomoreX, havetomoreY = TLCC_table(data, all_col_list, 14)

# COMMAND ----------

print(havetomoreX)
print(havetomoreY)

# COMMAND ----------

for i in range(len(havetomoreX)):
    tlccdata = TLCC(data[havetomoreX[i]], data[havetomoreY[i]], 150)
    print(havetomoreX[i], havetomoreY[i], np.argmax(tlccdata), np.round(max(tlccdata),4))

# COMMAND ----------

# allì¹´í…Œê³ ë¦¬ í”¼ì²˜ë³„ ì‹œì°¨ìƒê´€ë¶„ì„ ì‹¤í—˜ ê²°ê³¼
- ëŒ€ë¶€ë¶„ ì¹´í…Œê³ ë¦¬ì˜ ì‹œì°¨ìƒê´€ê³„ìˆ˜ê°€ ê°€ì¥ ë†’ì„ ë–„ëŠ” lag=0 ì¦‰, ë™í–‰ì„±ì„ ë³´ì¸ë‹¤.
- ì‹œì°¨ì§€ì—°ë˜ëŠ” ê²½ìš°ëŠ”,"avgusd"ê°€ í›„í–‰ì¼ë•Œ 71~100ì˜ ì§€ì—°ì„ ë³´ì¸ë‹¤.
- ì‹œì°¨ìƒê´€ì„±ì´ ë‚®ì€ ê²½ìš°ëŠ” primary salesê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•˜ë‹¤. 0.6~0.8  ì„ í–‰/í›„í–‰ ëª¨ë‘ ë‚®ìŒ

-  avgusd-buyer 71ì„ ëŒ€í‘œë¡œ ê³µì ë¶„ ê²€ì¦í•´ë³´ì

# COMMAND ----------

# MAGIC %md
# MAGIC ## ì‹œì°¨ìƒê´€ê³„ìˆ˜ ì˜ˆì œ ë”°ë¼í•˜ê¸°..
# MAGIC - ì–´ë–»ê²Œ í•´ì„ì„ í•´ì•¼í• ì§€ ëª¨ë¥´ê² ë‹¤

# COMMAND ----------

def crosscorr(datax, datay, lag=0, wrap=False):
# """ Lag-N cross correlation. 
# Shifted data filled with NaNs 

# Parameters
# ----------
# lag : int, default 0
# datax, datay : pandas.Series objects of equal length
# wrap : NaN ì±„ìš°ëŠ” ê²ƒ. shift í•˜ë©´ì„œ ì‚¬ë¼ì§„ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ì±„ìš°ê¸°. ê°’ì´ ìˆœí™˜ë˜ê²Œ ëœë‹¤. wrap=False ì´ë©´ NaNì€ dropí•˜ê³  correlation êµ¬í•œë‹¤.
# Returns
# ----------
# crosscorr : float
# """
    if wrap:
        shiftedy = datay.shift(lag)
        shiftedy.iloc[:lag] = datay.iloc[-lag:].values
        return datax.corr(shiftedy)
    else: 
        return datax.corr(datay.shift(lag))

# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. offset ì–‘ìˆ˜ì´ë¯€ë¡œ s2ê°€ ì„ í–‰í•œë‹¤? 59ì¼ì°¨?
s1 = data['game_average_usd']
s2 = data['collectible_average_usd']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------



# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. offset ì–‘ìˆ˜ì´ë¯€ë¡œ s2ê°€ ì„ í–‰í•œë‹¤? ì´ê±´ ì´ìƒí•œë°.. í‰ê· ê°€ë³´ë‹¤ ë§ˆì¼“ì´ ì„ í–‰í•œë‹¤ê³ ?. ì„¸ì¼ì¦ˆë‘ ë¹„êµí•´ë´ì•¼í•˜ë‚˜.
s1 = data['all_average_usd']
s2 = data['all_sales_usd']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------

#  í•´ì„ì–´ì¼€í•¨.. ëª¨ë¥´ê² ë‹¤.
s1 = data['all_average_usd']
s2 = data['all_number_of_sales']

rs = [crosscorr(s1,s2, lag) for lag in range(-300, 300)]
offset = np.floor(len(rs)/2)-np.argmax(rs) # ìµœëŒ€ correlation ê°’ ê°€ì§€ëŠ” offset ê³„ì‚°

f,ax=plt.subplots(figsize=(30,5))
# print(rs)
ax.plot(rs)
ax.axvline(np.ceil(len(rs)/2),color='k',linestyle='--',label='Center')
ax.axvline(np.argmax(rs),color='r',linestyle='--',label='Peak synchrony')
ax.set(title=f'Offset = {offset} \nS1 leads <> S2 leads', xlabel='Offset',ylabel='Pearson r')
# ax.set_xticks(range(-300, 300))
ax.set_xticklabels([-300, -150, -50, 0, 50, 150, 300])
plt.legend()

# Offsetì´ ì™¼ìª½ì— ìˆìœ¼ë©´, S1ì´ ë¦¬ë“œí•˜ê³¼ S2ê°€ ë”°ë¼ì˜¤ëŠ” ê²ƒ
# shift(-150)ì´ d2ì— ëŒ€í•´ì„œ ì ìš©ë˜ê³ , d2ì˜ ë¯¸ë˜ì™€ d1ì˜ í˜„ì¬ê°„ì— correlation ê³„ì‚° í•˜ëŠ” ê²ƒ. ì¦‰, offsetì´ ìŒìˆ˜ì´ë©´ d1ì´ ì„ í–‰í•œë‹¤ëŠ” ëœ»
# ì´ê²ƒë„ ê²°êµ­ global levelë¡œ correlation ì¸¡ì •í•˜ëŠ” ê²ƒ. ì‹œì°¨ ë‘ë©´ì„œ.

# COMMAND ----------

# MAGIC %md
# MAGIC ### ê¸°ê°„ ì§€ì—°ëœ ìƒí˜¸ ìƒê´€
# MAGIC - ì´ê²ƒë„ ë­˜ì–´ë–»ê²Œ ë´ì•¼í• ì§€ ëª¨ë¥´ê² ë‹¤.

# COMMAND ----------

data.shape[0]//20

# COMMAND ----------

import seaborn as sb

# COMMAND ----------

no_splits = 30
samples_per_split = data.shape[0]//no_splits
rss=[]

for t in range(0, no_splits):
    d1 = data['game_average_usd'].iloc[(t)*samples_per_split:(t+1)*samples_per_split]
    d2 = data['collectible_average_usd'].iloc[(t)*samples_per_split:(t+1)*samples_per_split]
    rs = [crosscorr(d1,d2, lag) for lag in range(-300,300)]
    rss.append(rs)
rss = pd.DataFrame(rss)
f,ax = plt.subplots(figsize=(30,10))
sb.heatmap(rss, cmap='RdBu_r',ax=ax)
ax.set(title=f'Windowed Time Lagged Cross Correlation', xlabel='Offset',ylabel='Window epochs')
# ax.set_xticks([0, 50, 100, 151, 201, 251, 301])
# ax.set_xticklabels([-150, -100, -50, 0, 50, 100, 150]);

# Rolling window time lagged cross correlation
window_size = 300 #samples
t_start = 0
t_end = t_start + window_size
step_size = 30
rss=[]
while t_end < 1704:
    d1 = data['game_average_usd'].iloc[t_start:t_end]
    d2 = data['collectible_average_usd'].iloc[t_start:t_end]
    rs = [crosscorr(d1,d2, lag, wrap=False) for lag in range(-300,300)]
    rss.append(rs)
    t_start = t_start + step_size
    t_end = t_end + step_size
rss = pd.DataFrame(rss)

f,ax = plt.subplots(figsize=(30,10))
sb.heatmap(rss,cmap='RdBu_r',ax=ax)
ax.set(title=f'Rolling Windowed Time Lagged Cross Correlation',xlabel='Offset',ylabel='Epochs')
# ax.set_xticks([0, 50, 100, 151, 201, 251, 301])
# ax.set_xticklabels([-150, -100, -50, 0, 50, 100, 150]);

# COMMAND ----------

# MAGIC %md
# MAGIC ## ê³µì ë¶„ ê²€ì¦(ê·¸ë ˆì¸ì € ì¸ê³¼ê²€ì •)
# MAGIC - ìƒê´€ê´€ê³„ì™€ ìœ ì‚¬í•œ ê³µì ë¶„ì€ ë‘ ë³€ìˆ˜ê°„ì˜ ë¹„ìœ¨ì´ í‰ê· ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¬ë¼ì§ì„ ì˜ë¯¸í•œë‹¤
# MAGIC - ê³µì ë¶„ ê´€ê³„ëŠ”, ë‹¨ê¸°ì ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ íŒ¨í„´ì„ ë³´ì´ì§€ë§Œ ì¥ê¸°ì ìœ¼ë¡œ ë³¼ ë•Œ ì¼ì •í•œ ê´€ê³„ê°€ ìˆìŒì„ ì˜ë¯¸í•¨
# MAGIC - statsmodels.coint ëŠ” engle-granger ê¸°ë°˜
# MAGIC - ê·€ë¬´ê°€ì„¤ : ì„œë¡œ ê³µì ë¶„ ê´€ê³„ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.ì¦‰, p-valueê°’ì´ 5%ë³´ë‹¤ ì‘ì„ ë•Œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì—¬ ê³µì ë¶„ê´€ê³„ê°€ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.
# MAGIC 
# MAGIC - https://mkjjo.github.io/finance/2019/01/25/pair_trading.html
# MAGIC - https://lsjsj92.tistory.com/584

# COMMAND ----------

import statsmodels.tsa.stattools as ts

# COMMAND ----------

# ê³µì ë¶„ ê³„ì‚°
X = data['game_average_usd']
Y = data['collectible_average_usd']

(Y/X).plot(figsize=(15,7))
plt.axhline((Y/X).mean(), color='red', linestyle='--')
plt.xlabel('Time')
plt.title('collectible / game Ratio')
plt.legend(['collectible / game Ratio', 'Mean'])
plt.show()

# COMMAND ----------

# rawë°ì´í„°
score, pvalue, _ = ts.coint(X,Y)
print('Rawdata Correlation: ' + str(X.corr(Y)))
print('Rawdata Cointegration test p-value: ' + str(pvalue))
# # logë°ì´í„°
# X = np.log1p(X)
# Y = np.log1p(Y)
# score, pvalue, _ = ts.coint(X,Y)
# print('Log data Correlation: ' + str(X.corr(Y)))
# print('Log data Cointegration test p-value: ' + str(pvalue))

# COMMAND ----------

# ê²Œì„í‰ê· ê°€ ì™€ ì½œë ‰í„°ë¸” í‰ê· ê°€
# ê³µì ë¶„ì˜ pvalueê°€ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•œë‹¤. ì„œë¡œ ê³µì ë¶„ê´€ê³„ ì—†ìŒ
# ë¡œê·¸ë³€í™˜í•˜ë‹ˆê¹Œ ê´€ê³„ì„±ì´ ë” ë‚®ì•„ì§„ë‹¤. ì•ˆë³´ëŠ”ê²Œ ë§ëŠ” ë“¯

# COMMAND ----------

# ê³µì ë¶„ ê³„ì‚°
X = data['all_average_usd']
Y = data['all_sales_usd']
(Y/X).plot(figsize=(15,7))
plt.axhline((Y/X).mean(), color='red', linestyle='--')
plt.xlabel('Time')
plt.title('all_sales_usd / all_avgusd  Ratio')
plt.legend(['all_sales_usd / all_avgusd  Ratio', 'Mean'])
plt.show()

# COMMAND ----------

# rawë°ì´í„°
score, pvalue, _ = ts.coint(X,Y)
print('Rawdata Correlation: ' + str(X.corr(Y)))
print('Rawdata Cointegration test p-value: ' + str(pvalue))
# # logë°ì´í„°
# X = np.log1p(X)
# Y = np.log1p(Y)
# score, pvalue, _ = ts.coint(X,Y)
# print('Log data Correlation: ' + str(X.corr(Y)))
# print('Log data Cointegration test p-value: ' + str(pvalue))

# COMMAND ----------

# ì „ì²´í‰ê· ê°€ ì™€ ì „ì²´íŒë§¤ê°€
# ê³µì ë¶„ì˜ pvalueê°€ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•œë‹¤. ì„œë¡œ ê³µì ë¶„ê´€ê³„ ì—†ìŒ

# COMMAND ----------

# ê³µì ë¶„ ê³„ì‚°
X = data['all_average_usd']
Y = data['all_number_of_sales']
(Y/X).plot(figsize=(15,7))
plt.axhline((Y/X).mean(), color='red', linestyle='--')
plt.xlabel('Time')
plt.title('all_sales/ all_avgusd Ratio')
plt.legend(['all_sales / all_avgusd Ratio', 'Mean'])
plt.show()

# COMMAND ----------

# rawë°ì´í„°
score, pvalue, _ = ts.coint(X,Y)
print('Rawdata Correlation: ' + str(X.corr(Y)))
print('Rawdata Cointegration test p-value: ' + str(pvalue))
# # logë°ì´í„°
# X = np.log1p(X)
# Y = np.log1p(Y)
# score, pvalue, _ = ts.coint(X,Y)
# print('Log data Correlation: ' + str(X.corr(Y)))
# print('Log data Cointegration test p-value: ' + str(pvalue))

# COMMAND ----------

# rawë°ì´í„°
score, pvalue, _ = ts.coint(X,Y, trend='ct')
print('Rawdata Correlation: ' + str(X.corr(Y)))
print('Rawdata Cointegration test p-value: ' + str(pvalue))
# logë°ì´í„°
X = np.log1p(X)
Y = np.log1p(Y)
score, pvalue, _ = ts.coint(X,Y)
print('Log data Correlation: ' + str(X.corr(Y)))
print('Log data Cointegration test p-value: ' + str(pvalue))

# COMMAND ----------

# ì „ì²´í‰ê· ê°€ ì™€ ì „ì²´íŒë§¤ìˆ˜
# ê³µì ë¶„ì˜ pvalueê°€ 0.05ë¥¼ ì´ˆê³¼í•˜ì—¬ ê·€ë¬´ê°€ì„¤ì„ ì±„íƒí•œë‹¤. ì„œë¡œ ê³µì ë¶„ê´€ê³„ ì—†ìŒ

# COMMAND ----------

# MAGIC %md
# MAGIC ## ëŒ€í‘œ ê´€ê³„, lagë³„ ê³µì ë¶„ ê²€ì¦í•˜ê¸°
# MAGIC - allì¹´í…Œê³ ë¦¬ ëŒ€í‘œ : avgusd-buyer 71, ê³µì ë¶„ ê²€ì¦ ì„±ê³µ(min=94)
# MAGIC   - ì¢…í•© : ì „ì²´ í‰ê· ê°€ì™€ ì „ì²´ êµ¬ë§¤ììˆ˜ëŠ” ì¥ê¸°ê´€ì ì—ì„œ ì¸ê³¼ì„±ì´ ìˆë‹¤. í‰ê· ê°€ê°€ 71~94ì¼ ì •ë„ ì„ í–‰í•œë‹¤.
# MAGIC - avgusdí”¼ì²˜ ëŒ€í‘œ : collectible-game 59, ê³µì ë¶„ ê²€ì¦ ì„±ê³µ(min=66), 
# MAGIC   - ì¢…í•© : ì½œë ‰í„°ë¸” í‰ê· ê°€ì™€ ê²Œì„ í‰ê· ê°€ëŠ” ì¥ê¸°ì ìœ¼ë¡œ ì¸ê³¼ì„±ì´ ìˆë‹¤. ì½œë ‰í„°ë“¤ì´ 2ë‹¬ ì •ë„ ì„ í–‰í•œë‹¤.

# COMMAND ----------

#  ì‹œì°¨ìƒê´€ê³„ìˆ˜ ê³„ì‚°í•¨ìˆ˜
def coint_lag(X, Y, nlag):
#     score=[]
    pvalue=[]
    for i in range(nlag):
        _, p, _ = ts.coint(X,Y.shift(i, fill_value=0))
#         score.append(s)
        pvalue.append(p)
    return pvalue

# COMMAND ----------

X = data['collectible_average_usd']
Y = data['game_average_usd']
pval = coint_lag(X,Y, 100)
print(np.argmin(pval), '|', min(pval))
print(pval)

# COMMAND ----------

# 40 ì´í›„ pval 0.05 ë¯¸ë§Œìœ¼ë¡œ ê·€ë¬´ê°€ì„¤ ê¸°ê°í•˜ì—¬ ê³µì ë¶„ ê²€ì¦ì™„ë£Œ, ì¥ê¸° ê´€ê³„ ìˆìŒ
plt.figure(figsize=(30,10))
plt.plot(range(len(pval)), pval)
plt.hlines(0.05, xmin=0, xmax=len(pval), color='blue')
plt.show()

# COMMAND ----------

X = data['all_average_usd']
Y = data['all_unique_buyers']
# print(Y.shift(i, fill_value=0))
pval = coint_lag(X,Y, 100)
print(np.argmin(pval), '|', min(pval))
print(pval)
# s, p, _ = ts.coint(X,Y.shift(i))

# COMMAND ----------

# 20ì „í›„, 75 ì´í›„ê°€ pval 0.05 ë¯¸ë§Œìœ¼ë¡œ ê·€ë¬´ê°€ì„¤ ê¸°ê°í•˜ì—¬ ê³µì ë¶„ ê²€ì¦ì™„ë£Œ, ì¥ê¸° ê´€ê³„ ìˆìŒ
# 
plt.figure(figsize=(30,10))
plt.plot(range(len(pval)), pval)
plt.hlines(0.05, xmin=0, xmax=len(pval), color='blue')
plt.show()

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# ## ê³µì ë¶„ ê²€ì¦ê¸°(ì¹´í…Œê³ ë¦¬)
# def coint_table(data, col_list, nlag):

#     xcol_list = []
#     ycol_list = []
#     pval_list = []
# #     havetomoreX = []
# #     havetomoreY = []
    
#     for i in range(len(col_list)):
#         for j in range(1, len(col_list)):
#             if col_list[i] == col_list[j]:
#                 pass
#             else:
#                 xcol_list.append(col_list[i])
#                 ycol_list.append(col_list[j])
#                 _, pval = coint_lag(data[col_list[i]], data[col_list[j]], nlag)
#                 pval_list.append(pval)
                
#                 print(col_list[i], '|', col_list[j] )
#                 print(pval)

# COMMAND ----------

# coint_table(data, avgusd_col_list, 14)

# COMMAND ----------

# # avgusdí”¼ì²˜ì˜ ì¹´í…Œê³ ë¦¬ê°„ ê³µì ë¶„ ê²€ì¦

# avgusd_col_list
# for 






# COMMAND ----------

# allì¹´í…Œê³ ë¦¬ í”¼ì²˜ê°„ ê³µì ë¶„ ê²€ì¦

# COMMAND ----------

# ## TLCC table ìƒì„±ê¸°
# def TLCC_table(data, col_list, nlag):

#     xcol_list = []
#     ycol_list = []
#     TLCC_list = []
#     havetomoreX = []
#     havetomoreY = []

#     for i in range(len(col_list)):
#         for j in range(1, len(col_list)):
#             if col_list[i] == col_list[j]:
#                 pass
#             else:
#                 xcol_list.append(col_list[i])
#                 ycol_list.append(col_list[j])
#                 tlccdata = TLCC(data[col_list[i]], data[col_list[j]], nlag)
#                 TLCC_list.append(tlccdata)
# #                 print(col_list[i], col_list[j])
# #                 print(tlccdata)
# #                 print(np.argmax(tlccdata))
# #                 print(np.argmax(TLCC_list[i]))
#                 max_TLCC_idx = np.argmax(tlccdata)
#                 max_TLCC = np.round(max(tlccdata),4)
#                 if max_TLCC >= 0.7:
#                     result = 'ë†’ìŒ'
#                 elif max_TLCC > 0.3 and max_TLCC < 0.7:
#                     result = 'ë³´í†µ'
#                 else :
#                     result = 'ë‚®ìŒ'
#                 print(col_list[i], '|', col_list[j], '|', max_TLCC_idx, '|', max_TLCC, '|', result)
            
                
#                 if max_TLCC_idx == nlag-1:
#                     havetomoreX.append(col_list[i])
#                     havetomoreY.append(col_list[j])

#     return havetomoreX, havetomoreY
